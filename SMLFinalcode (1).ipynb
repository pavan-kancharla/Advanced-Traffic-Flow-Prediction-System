{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50fec3e7-b53a-42e3-b8f4-f5259ae4621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, dataframe, window_length=100):\n",
    "        # Perform the custom transformation\n",
    "        sliced_df = self.custom_transformation(dataframe.to_numpy(), window_length=window_length)\n",
    "        self.data = torch.tensor(sliced_df, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of trajectories\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the trajectory at the given index\n",
    "        return self.data[idx]\n",
    "\n",
    "    def custom_transformation(self, dataframe_array, window_length):\n",
    "        num_rows, num_cols = dataframe_array.shape\n",
    "        window_length += 1  # get one more column as targets\n",
    "\n",
    "        # Preallocate memory for the slices\n",
    "        sliced_data = np.lib.stride_tricks.sliding_window_view(dataframe_array, window_shape=(window_length,), axis=1)\n",
    "        \n",
    "        # Reshape into a flat 2D array for DataFrame-like output\n",
    "        sliced_data = sliced_data.reshape(-1, window_length)\n",
    "\n",
    "        return sliced_data\n",
    "    \n",
    "# Implement your model\n",
    "# Implement your model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Layer dimensions\n",
    "        self.h1_size = hidden_size\n",
    "        self.h2_size = hidden_size // 2\n",
    "        self.h3_size = hidden_size // 4\n",
    "        \n",
    "        # Input processing\n",
    "        self.input_norm = nn.LayerNorm(input_size)\n",
    "        self.input_dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Main layers\n",
    "        self.fc1 = nn.Linear(input_size, self.h1_size)\n",
    "        self.bn1 = nn.BatchNorm1d(self.h1_size)\n",
    "        \n",
    "        self.fc2 = nn.Linear(self.h1_size, self.h2_size)\n",
    "        self.bn2 = nn.BatchNorm1d(self.h2_size)\n",
    "        \n",
    "        self.fc3 = nn.Linear(self.h2_size, self.h3_size)\n",
    "        self.bn3 = nn.BatchNorm1d(self.h3_size)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc_out = nn.Linear(self.h3_size, output_size)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.silu = nn.SiLU()  # More advanced than ReLU\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input processing\n",
    "        x = self.input_norm(x)\n",
    "        x = self.input_dropout(x)\n",
    "        \n",
    "        # First block\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.silu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second block\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.silu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Third block\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.silu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Output\n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0abe772-ad8a-4260-aee5-86dcf1fed722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the relative path of a file in the current working directory\n",
    "train_path = os.path.join('/home/pkancha3/Desktop/train.csv')\n",
    "val_path = os.path.join('/home/pkancha3/Desktop/val.csv')\n",
    "test_path = os.path.join('/home/pkancha3/Desktop/test.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path, header = 0).drop('ids', axis=1)\n",
    "val_df = pd.read_csv(val_path, header = 0).drop('ids', axis=1)\n",
    "test_df = pd.read_csv(test_path, header = 0).drop('ids', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035e74f2-8bf3-46b5-8691-cc68b374eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/1 [00:00<?, ?epoch/s]\n",
      "Epoch 1: 0batch [00:00, ?batch/s]\u001b[A\n",
      "Epoch 1: 1batch [00:00,  2.27batch/s]\u001b[A\n",
      "Epoch 1: 51batch [00:00, 123.63batch/s]\u001b[A\n",
      "Epoch 1: 102batch [00:00, 222.45batch/s]\u001b[A\n",
      "Epoch 1: 153batch [00:00, 298.29batch/s]\u001b[A\n",
      "Epoch 1: 204batch [00:00, 355.33batch/s]\u001b[A\n",
      "Epoch 1: 255batch [00:00, 397.03batch/s]\u001b[A\n",
      "Epoch 1: 306batch [00:01, 427.19batch/s]\u001b[A\n",
      "Epoch 1: 357batch [00:01, 449.27batch/s]\u001b[A\n",
      "Epoch 1: 408batch [00:01, 465.13batch/s]\u001b[A\n",
      "Epoch 1: 459batch [00:01, 475.56batch/s]\u001b[A\n",
      "Epoch 1: 509batch [00:01, 482.23batch/s]\u001b[A\n",
      "Epoch 1: 559batch [00:01, 486.83batch/s]\u001b[A\n",
      "Epoch 1: 609batch [00:01, 490.29batch/s]\u001b[A\n",
      "Epoch 1: 659batch [00:01, 492.56batch/s]\u001b[A\n",
      "Epoch 1: 709batch [00:01, 494.34batch/s]\u001b[A\n",
      "Epoch 1: 759batch [00:01, 495.45batch/s]\u001b[A\n",
      "Epoch 1: 809batch [00:02, 496.20batch/s]\u001b[A\n",
      "Epoch 1: 859batch [00:02, 497.16batch/s]\u001b[A\n",
      "Epoch 1: 909batch [00:02, 497.58batch/s]\u001b[A\n",
      "Epoch 1: 959batch [00:02, 497.83batch/s]\u001b[A\n",
      "Epoch 1: 1009batch [00:02, 498.06batch/s]\u001b[A\n",
      "Epoch 1: 1059batch [00:02, 498.25batch/s]\u001b[A\n",
      "Epoch 1: 1109batch [00:02, 498.31batch/s]\u001b[A\n",
      "Epoch 1: 1159batch [00:02, 498.48batch/s]\u001b[A\n",
      "Epoch 1: 1209batch [00:02, 498.56batch/s]\u001b[A\n",
      "Epoch 1: 1259batch [00:02, 498.38batch/s]\u001b[A\n",
      "Epoch 1: 1309batch [00:03, 498.24batch/s]\u001b[A\n",
      "Epoch 1: 1359batch [00:03, 498.34batch/s]\u001b[A\n",
      "Epoch 1: 1409batch [00:03, 498.52batch/s]\u001b[A\n",
      "Epoch 1: 1459batch [00:03, 498.52batch/s]\u001b[A\n",
      "Epoch 1: 1509batch [00:03, 498.55batch/s]\u001b[A\n",
      "Epoch 1: 1559batch [00:03, 498.51batch/s]\u001b[A\n",
      "Epoch 1: 1609batch [00:03, 498.66batch/s]\u001b[A\n",
      "Epoch 1: 1659batch [00:03, 498.47batch/s]\u001b[A\n",
      "Epoch 1: 1709batch [00:03, 498.39batch/s]\u001b[A\n",
      "Epoch 1: 1759batch [00:03, 498.36batch/s]\u001b[A\n",
      "Epoch 1: 1809batch [00:04, 498.49batch/s]\u001b[A\n",
      "Epoch 1: 1859batch [00:04, 498.58batch/s]\u001b[A\n",
      "Epoch 1: 1909batch [00:04, 498.35batch/s]\u001b[A\n",
      "Epoch 1: 1959batch [00:04, 498.71batch/s]\u001b[A\n",
      "Epoch 1: 2009batch [00:04, 498.82batch/s]\u001b[A\n",
      "Epoch 1: 2059batch [00:04, 498.49batch/s]\u001b[A\n",
      "Epoch 1: 2109batch [00:04, 498.57batch/s]\u001b[A\n",
      "Epoch 1: 2159batch [00:04, 498.57batch/s]\u001b[A\n",
      "Epoch 1: 2209batch [00:04, 498.45batch/s]\u001b[A\n",
      "Epoch 1: 2259batch [00:04, 498.60batch/s]\u001b[A\n",
      "Epoch 1: 2309batch [00:05, 498.59batch/s]\u001b[A\n",
      "Epoch 1: 2359batch [00:05, 498.55batch/s]\u001b[A\n",
      "Epoch 1: 2409batch [00:05, 498.18batch/s]\u001b[A\n",
      "Epoch 1: 2459batch [00:05, 498.39batch/s]\u001b[A\n",
      "Epoch 1: 2509batch [00:05, 498.42batch/s]\u001b[A\n",
      "Epoch 1: 2559batch [00:05, 498.17batch/s]\u001b[A\n",
      "Epoch 1: 2609batch [00:05, 498.07batch/s]\u001b[A\n",
      "Epoch 1: 2659batch [00:05, 498.28batch/s]\u001b[A\n",
      "Epoch 1: 2709batch [00:05, 498.27batch/s]\u001b[A\n",
      "Epoch 1: 2759batch [00:05, 498.21batch/s]\u001b[A\n",
      "Epoch 1: 2809batch [00:06, 498.33batch/s]\u001b[A\n",
      "Epoch 1: 2859batch [00:06, 498.37batch/s]\u001b[A\n",
      "Epoch 1: 2909batch [00:06, 498.37batch/s]\u001b[A\n",
      "Epoch 1: 2959batch [00:06, 498.31batch/s]\u001b[A\n",
      "Epoch 1: 3009batch [00:06, 498.19batch/s]\u001b[A\n",
      "Epoch 1: 3059batch [00:06, 498.23batch/s]\u001b[A\n",
      "Epoch 1: 3109batch [00:06, 498.32batch/s]\u001b[A\n",
      "Epoch 1: 3159batch [00:06, 498.36batch/s]\u001b[A\n",
      "Epoch 1: 3209batch [00:06, 498.15batch/s]\u001b[A\n",
      "Epoch 1: 3259batch [00:06, 498.13batch/s]\u001b[A\n",
      "Epoch 1: 3309batch [00:07, 498.17batch/s]\u001b[A\n",
      "Epoch 1: 3359batch [00:07, 498.20batch/s]\u001b[A\n",
      "Epoch 1: 3409batch [00:07, 498.31batch/s]\u001b[A\n",
      "Epoch 1: 3459batch [00:07, 498.13batch/s]\u001b[A\n",
      "Epoch 1: 3509batch [00:07, 498.15batch/s]\u001b[A\n",
      "Epoch 1: 3559batch [00:07, 498.17batch/s]\u001b[A\n",
      "Epoch 1: 3609batch [00:07, 498.30batch/s]\u001b[A\n",
      "Epoch 1: 3659batch [00:07, 498.29batch/s]\u001b[A\n",
      "Epoch 1: 3709batch [00:07, 498.12batch/s]\u001b[A\n",
      "Epoch 1: 3759batch [00:07, 498.04batch/s]\u001b[A\n",
      "Epoch 1: 3809batch [00:08, 498.20batch/s]\u001b[A\n",
      "Epoch 1: 3859batch [00:08, 497.94batch/s]\u001b[A\n",
      "Epoch 1: 3909batch [00:08, 498.21batch/s]\u001b[A\n",
      "Epoch 1: 3959batch [00:08, 498.24batch/s]\u001b[A\n",
      "Epoch 1: 4009batch [00:08, 498.39batch/s]\u001b[A\n",
      "Epoch 1: 4059batch [00:08, 496.80batch/s]\u001b[A\n",
      "Epoch 1: 4109batch [00:08, 497.24batch/s]\u001b[A\n",
      "Epoch 1: 4159batch [00:08, 497.80batch/s]\u001b[A\n",
      "Epoch 1: 4209batch [00:08, 497.99batch/s]\u001b[A\n",
      "Epoch 1: 4259batch [00:08, 498.13batch/s]\u001b[A\n",
      "Epoch 1: 4309batch [00:09, 498.11batch/s]\u001b[A\n",
      "Epoch 1: 4359batch [00:09, 498.44batch/s]\u001b[A\n",
      "Epoch 1: 4409batch [00:09, 498.31batch/s]\u001b[A\n",
      "Epoch 1: 4459batch [00:09, 498.48batch/s]\u001b[A\n",
      "Epoch 1: 4509batch [00:09, 498.07batch/s]\u001b[A\n",
      "Epoch 1: 4559batch [00:09, 495.67batch/s]\u001b[A\n",
      "Epoch 1: 4609batch [00:09, 496.50batch/s]\u001b[A\n",
      "Epoch 1: 4659batch [00:09, 497.04batch/s]\u001b[A\n",
      "Epoch 1: 4709batch [00:09, 497.29batch/s]\u001b[A\n",
      "Epoch 1: 4759batch [00:09, 496.07batch/s]\u001b[A\n",
      "Epoch 1: 4809batch [00:10, 495.20batch/s]\u001b[A\n",
      "Epoch 1: 4859batch [00:10, 486.53batch/s]\u001b[A\n",
      "Epoch 1: 4909batch [00:10, 489.74batch/s]\u001b[A\n",
      "Epoch 1: 4959batch [00:10, 492.04batch/s]\u001b[A\n",
      "Epoch 1: 5009batch [00:10, 494.05batch/s]\u001b[A\n",
      "Epoch 1: 5059batch [00:10, 495.28batch/s]\u001b[A\n",
      "Epoch 1: 5109batch [00:10, 495.92batch/s]\u001b[A\n",
      "Epoch 1: 5159batch [00:10, 496.58batch/s]\u001b[A\n",
      "Epoch 1: 5209batch [00:10, 496.88batch/s]\u001b[A\n",
      "Epoch 1: 5259batch [00:11, 495.19batch/s]\u001b[A\n",
      "Epoch 1: 5309batch [00:11, 495.82batch/s]\u001b[A\n",
      "Epoch 1: 5359batch [00:11, 496.36batch/s]\u001b[A\n",
      "Epoch 1: 5409batch [00:11, 496.96batch/s]\u001b[A\n",
      "Epoch 1: 5459batch [00:11, 497.36batch/s]\u001b[A\n",
      "Epoch 1: 5509batch [00:11, 497.51batch/s]\u001b[A\n",
      "Epoch 1: 5559batch [00:11, 497.75batch/s]\u001b[A\n",
      "Epoch 1: 5609batch [00:11, 497.81batch/s]\u001b[A\n",
      "Epoch 1: 5659batch [00:11, 497.80batch/s]\u001b[A\n",
      "Epoch 1: 5709batch [00:11, 498.11batch/s]\u001b[A\n",
      "Epoch 1: 5759batch [00:12, 497.88batch/s]\u001b[A\n",
      "Epoch 1: 5809batch [00:12, 497.97batch/s]\u001b[A\n",
      "Epoch 1: 5859batch [00:12, 498.15batch/s]\u001b[A\n",
      "Epoch 1: 5909batch [00:12, 498.11batch/s]\u001b[A\n",
      "Epoch 1: 5959batch [00:12, 497.89batch/s]\u001b[A\n",
      "Epoch 1: 6009batch [00:12, 497.97batch/s]\u001b[A\n",
      "Epoch 1: 6059batch [00:12, 498.00batch/s]\u001b[A\n",
      "Epoch 1: 6109batch [00:12, 498.17batch/s]\u001b[A\n",
      "Epoch 1: 6159batch [00:12, 498.24batch/s]\u001b[A\n",
      "Epoch 1: 6209batch [00:12, 498.30batch/s]\u001b[A\n",
      "Epoch 1: 6259batch [00:13, 498.11batch/s]\u001b[A\n",
      "Epoch 1: 6309batch [00:13, 498.12batch/s]\u001b[A\n",
      "Epoch 1: 6359batch [00:13, 498.29batch/s]\u001b[A\n",
      "Epoch 1: 6409batch [00:13, 498.26batch/s]\u001b[A\n",
      "Epoch 1: 6459batch [00:13, 498.30batch/s]\u001b[A\n",
      "Epoch 1: 6509batch [00:13, 498.19batch/s]\u001b[A\n",
      "Epoch 1: 6559batch [00:13, 498.07batch/s]\u001b[A\n",
      "Epoch 1: 6610batch [00:13, 500.59batch/s]\u001b[A\n",
      "Epoch 1: 6661batch [00:13, 502.85batch/s]\u001b[A\n",
      "Epoch 1: 6712batch [00:13, 503.59batch/s]\u001b[A\n",
      "Epoch 1: 6763batch [00:14, 503.99batch/s]\u001b[A\n",
      "Epoch 1: 6814batch [00:14, 503.96batch/s]\u001b[A\n",
      "Epoch 1: 6865batch [00:14, 503.74batch/s]\u001b[A\n",
      "Epoch 1: 6916batch [00:14, 501.89batch/s]\u001b[A\n",
      "Epoch 1: 6967batch [00:14, 500.94batch/s]\u001b[A\n",
      "Epoch 1: 7018batch [00:14, 500.07batch/s]\u001b[A\n",
      "Epoch 1: 7069batch [00:14, 499.53batch/s]\u001b[A\n",
      "Epoch 1: 7119batch [00:14, 498.99batch/s]\u001b[A\n",
      "Epoch 1: 7169batch [00:14, 498.75batch/s]\u001b[A\n",
      "Epoch 1: 7219batch [00:14, 498.56batch/s]\u001b[A\n",
      "Epoch 1: 7269batch [00:15, 498.34batch/s]\u001b[A\n",
      "Epoch 1: 7319batch [00:15, 498.23batch/s]\u001b[A\n",
      "Epoch 1: 7369batch [00:15, 498.22batch/s]\u001b[A\n",
      "Epoch 1: 7419batch [00:15, 497.96batch/s]\u001b[A\n",
      "Epoch 1: 7469batch [00:15, 497.87batch/s]\u001b[A\n",
      "Epoch 1: 7519batch [00:15, 497.89batch/s]\u001b[A\n",
      "Epoch 1: 7569batch [00:15, 497.66batch/s]\u001b[A\n",
      "Epoch 1: 7619batch [00:15, 497.71batch/s]\u001b[A\n",
      "Epoch 1: 7669batch [00:15, 497.87batch/s]\u001b[A\n",
      "Epoch 1: 7719batch [00:15, 497.95batch/s]\u001b[A\n",
      "Epoch 1: 7769batch [00:16, 497.83batch/s]\u001b[A\n",
      "Epoch 1: 7819batch [00:16, 497.87batch/s]\u001b[A\n",
      "Epoch 1: 7869batch [00:16, 497.75batch/s]\u001b[A\n",
      "Epoch 1: 7919batch [00:16, 497.81batch/s]\u001b[A\n",
      "Epoch 1: 7969batch [00:16, 497.90batch/s]\u001b[A\n",
      "Epoch 1: 8019batch [00:16, 497.84batch/s]\u001b[A\n",
      "Epoch 1: 8069batch [00:16, 497.66batch/s]\u001b[A\n",
      "Epoch 1: 8119batch [00:16, 497.49batch/s]\u001b[A\n",
      "Epoch 1: 8169batch [00:16, 497.39batch/s]\u001b[A\n",
      "Epoch 1: 8220batch [00:16, 500.56batch/s]\u001b[A\n",
      "Epoch 1: 8271batch [00:17, 500.87batch/s]\u001b[A\n",
      "Epoch 1: 8322batch [00:17, 500.05batch/s]\u001b[A\n",
      "Epoch 1: 8373batch [00:17, 499.40batch/s]\u001b[A\n",
      "Epoch 1: 8423batch [00:17, 499.18batch/s]\u001b[A\n",
      "Epoch 1: 8473batch [00:17, 498.93batch/s]\u001b[A\n",
      "Epoch 1: 8523batch [00:17, 498.82batch/s]\u001b[A\n",
      "Epoch 1: 8573batch [00:17, 498.57batch/s]\u001b[A\n",
      "Epoch 1: 8623batch [00:17, 498.31batch/s]\u001b[A\n",
      "Epoch 1: 8673batch [00:17, 498.21batch/s]\u001b[A\n",
      "Epoch 1: 8723batch [00:17, 498.28batch/s]\u001b[A\n",
      "Epoch 1: 8773batch [00:18, 498.20batch/s]\u001b[A\n",
      "Epoch 1: 8823batch [00:18, 498.17batch/s]\u001b[A\n",
      "Epoch 1: 8873batch [00:18, 497.93batch/s]\u001b[A\n",
      "Epoch 1: 8923batch [00:18, 497.84batch/s]\u001b[A\n",
      "Epoch 1: 8973batch [00:18, 497.75batch/s]\u001b[A\n",
      "Epoch 1: 9023batch [00:18, 497.79batch/s]\u001b[A\n",
      "Epoch 1: 9073batch [00:18, 496.17batch/s]\u001b[A\n",
      "Epoch 1: 9123batch [00:18, 496.65batch/s]\u001b[A\n",
      "Epoch 1: 9173batch [00:18, 497.17batch/s]\u001b[A\n",
      "Epoch 1: 9223batch [00:18, 497.36batch/s]\u001b[A\n",
      "Epoch 1: 9273batch [00:19, 497.66batch/s]\u001b[A\n",
      "Epoch 1: 9323batch [00:19, 497.77batch/s]\u001b[A\n",
      "Epoch 1: 9373batch [00:19, 497.94batch/s]\u001b[A\n",
      "Epoch 1: 9423batch [00:19, 497.97batch/s]\u001b[A\n",
      "Epoch 1: 9473batch [00:19, 497.95batch/s]\u001b[A\n",
      "Epoch 1: 9523batch [00:19, 498.08batch/s]\u001b[A\n",
      "Epoch 1: 9573batch [00:19, 498.22batch/s]\u001b[A\n",
      "Epoch 1: 9623batch [00:19, 497.90batch/s]\u001b[A\n",
      "Epoch 1: 9673batch [00:19, 498.09batch/s]\u001b[A\n",
      "Epoch 1: 9723batch [00:19, 498.15batch/s]\u001b[A\n",
      "Epoch 1: 9773batch [00:20, 496.35batch/s]\u001b[A\n",
      "Epoch 1: 9823batch [00:20, 495.13batch/s]\u001b[A\n",
      "Epoch 1: 9873batch [00:20, 486.33batch/s]\u001b[A\n",
      "Epoch 1: 9923batch [00:20, 489.55batch/s]\u001b[A\n",
      "Epoch 1: 9973batch [00:20, 491.98batch/s]\u001b[A\n",
      "Epoch 1: 10023batch [00:20, 493.81batch/s]\u001b[A\n",
      "Epoch 1: 10073batch [00:20, 495.06batch/s]\u001b[A\n",
      "Epoch 1: 10123batch [00:20, 495.95batch/s]\u001b[A\n",
      "Epoch 1: 10173batch [00:20, 496.58batch/s]\u001b[A\n",
      "Epoch 1: 10223batch [00:20, 496.88batch/s]\u001b[A\n",
      "Epoch 1: 10273batch [00:21, 497.01batch/s]\u001b[A\n",
      "Epoch 1: 10323batch [00:21, 496.96batch/s]\u001b[A\n",
      "Epoch 1: 10373batch [00:21, 497.34batch/s]\u001b[A\n",
      "Epoch 1: 10423batch [00:21, 497.71batch/s]\u001b[A\n",
      "Epoch 1: 10473batch [00:21, 498.08batch/s]\u001b[A\n",
      "Epoch 1: 10523batch [00:21, 498.00batch/s]\u001b[A\n",
      "Epoch 1: 10573batch [00:21, 498.08batch/s]\u001b[A\n",
      "Epoch 1: 10623batch [00:21, 498.02batch/s]\u001b[A\n",
      "Epoch 1: 10673batch [00:21, 498.20batch/s]\u001b[A\n",
      "Epoch 1: 10723batch [00:21, 498.12batch/s]\u001b[A\n",
      "Epoch 1: 10773batch [00:22, 497.54batch/s]\u001b[A\n",
      "Epoch 1: 10823batch [00:22, 497.62batch/s]\u001b[A\n",
      "Epoch 1: 10873batch [00:22, 497.82batch/s]\u001b[A\n",
      "Epoch 1: 10923batch [00:22, 497.79batch/s]\u001b[A\n",
      "Epoch 1: 10973batch [00:22, 497.85batch/s]\u001b[A\n",
      "Epoch 1: 11023batch [00:22, 497.89batch/s]\u001b[A\n",
      "Epoch 1: 11073batch [00:22, 498.07batch/s]\u001b[A\n",
      "Epoch 1: 11123batch [00:22, 497.82batch/s]\u001b[A\n",
      "Epoch 1: 11173batch [00:22, 497.84batch/s]\u001b[A\n",
      "Epoch 1: 11223batch [00:22, 497.79batch/s]\u001b[A\n",
      "Epoch 1: 11273batch [00:23, 497.85batch/s]\u001b[A\n",
      "Epoch 1: 11323batch [00:23, 497.80batch/s]\u001b[A\n",
      "Epoch 1: 11373batch [00:23, 497.66batch/s]\u001b[A\n",
      "Epoch 1: 11423batch [00:23, 497.70batch/s]\u001b[A\n",
      "Epoch 1: 11473batch [00:23, 497.75batch/s]\u001b[A\n",
      "Epoch 1: 11523batch [00:23, 497.95batch/s]\u001b[A\n",
      "Epoch 1: 11573batch [00:23, 498.03batch/s]\u001b[A\n",
      "Epoch 1: 11623batch [00:23, 498.16batch/s]\u001b[A\n",
      "Epoch 1: 11673batch [00:23, 498.22batch/s]\u001b[A\n",
      "Epoch 1: 11723batch [00:23, 498.13batch/s]\u001b[A\n",
      "Epoch 1: 11773batch [00:24, 498.09batch/s]\u001b[A\n",
      "Epoch 1: 11823batch [00:24, 498.05batch/s]\u001b[A\n",
      "Epoch 1: 11873batch [00:24, 497.94batch/s]\u001b[A\n",
      "Epoch 1: 11923batch [00:24, 497.94batch/s]\u001b[A\n",
      "Epoch 1: 11973batch [00:24, 497.76batch/s]\u001b[A\n",
      "Epoch 1: 12023batch [00:24, 497.40batch/s]\u001b[A\n",
      "Epoch 1: 12073batch [00:24, 497.24batch/s]\u001b[A\n",
      "Epoch 1: 12123batch [00:24, 497.23batch/s]\u001b[A\n",
      "Epoch 1: 12173batch [00:24, 497.11batch/s]\u001b[A\n",
      "Epoch 1: 12223batch [00:24, 497.11batch/s]\u001b[A\n",
      "Epoch 1: 12273batch [00:25, 497.01batch/s]\u001b[A\n",
      "Epoch 1: 12323batch [00:25, 497.02batch/s]\u001b[A\n",
      "Epoch 1: 12373batch [00:25, 497.14batch/s]\u001b[A\n",
      "Epoch 1: 12423batch [00:25, 497.03batch/s]\u001b[A\n",
      "Epoch 1: 12473batch [00:25, 497.00batch/s]\u001b[A\n",
      "Epoch 1: 12523batch [00:25, 496.97batch/s]\u001b[A\n",
      "Epoch 1: 12573batch [00:25, 497.16batch/s]\u001b[A\n",
      "Epoch 1: 12623batch [00:25, 497.25batch/s]\u001b[A\n",
      "Epoch 1: 12673batch [00:25, 497.12batch/s]\u001b[A\n",
      "Epoch 1: 12723batch [00:25, 497.51batch/s]\u001b[A\n",
      "Epoch 1: 12773batch [00:26, 497.55batch/s]\u001b[A\n",
      "Epoch 1: 12823batch [00:26, 497.56batch/s]\u001b[A\n",
      "Epoch 1: 12873batch [00:26, 497.78batch/s]\u001b[A\n",
      "Epoch 1: 12923batch [00:26, 497.79batch/s]\u001b[A\n",
      "Epoch 1: 12973batch [00:26, 497.86batch/s]\u001b[A\n",
      "Epoch 1: 13023batch [00:26, 497.97batch/s]\u001b[A\n",
      "Epoch 1: 13073batch [00:26, 498.00batch/s]\u001b[A\n",
      "Epoch 1: 13123batch [00:26, 498.16batch/s]\u001b[A\n",
      "Epoch 1: 13173batch [00:26, 498.01batch/s]\u001b[A\n",
      "Epoch 1: 13223batch [00:26, 497.88batch/s]\u001b[A\n",
      "Epoch 1: 13273batch [00:27, 497.96batch/s]\u001b[A\n",
      "Epoch 1: 13323batch [00:27, 497.71batch/s]\u001b[A\n",
      "Epoch 1: 13373batch [00:27, 497.62batch/s]\u001b[A\n",
      "Epoch 1: 13423batch [00:27, 497.86batch/s]\u001b[A\n",
      "Epoch 1: 13473batch [00:27, 497.74batch/s]\u001b[A\n",
      "Epoch 1: 13523batch [00:27, 497.39batch/s]\u001b[A\n",
      "Epoch 1: 13573batch [00:27, 497.53batch/s]\u001b[A\n",
      "Epoch 1: 13623batch [00:27, 497.62batch/s]\u001b[A\n",
      "Epoch 1: 13673batch [00:27, 497.65batch/s]\u001b[A\n",
      "Epoch 1: 13723batch [00:28, 497.48batch/s]\u001b[A\n",
      "Epoch 1: 13773batch [00:28, 497.38batch/s]\u001b[A\n",
      "Epoch 1: 13823batch [00:28, 497.61batch/s]\u001b[A\n",
      "Epoch 1: 13873batch [00:28, 497.65batch/s]\u001b[A\n",
      "Epoch 1: 13923batch [00:28, 497.92batch/s]\u001b[A\n",
      "Epoch 1: 13973batch [00:28, 497.95batch/s]\u001b[A\n",
      "Epoch 1: 14023batch [00:28, 497.52batch/s]\u001b[A\n",
      "Epoch 1: 14073batch [00:28, 495.84batch/s]\u001b[A\n",
      "Epoch 1: 14123batch [00:28, 496.53batch/s]\u001b[A\n",
      "Epoch 1: 14173batch [00:28, 496.96batch/s]\u001b[A\n",
      "Epoch 1: 14223batch [00:29, 497.26batch/s]\u001b[A\n",
      "Epoch 1: 14273batch [00:29, 497.37batch/s]\u001b[A\n",
      "Epoch 1: 14323batch [00:29, 497.51batch/s]\u001b[A\n",
      "Epoch 1: 14373batch [00:29, 497.68batch/s]\u001b[A\n",
      "Epoch 1: 14423batch [00:29, 497.94batch/s]\u001b[A\n",
      "Epoch 1: 14473batch [00:29, 497.99batch/s]\u001b[A\n",
      "Epoch 1: 14523batch [00:29, 497.93batch/s]\u001b[A\n",
      "Epoch 1: 14573batch [00:29, 497.54batch/s]\u001b[A\n",
      "Epoch 1: 14623batch [00:29, 497.88batch/s]\u001b[A\n",
      "Epoch 1: 14673batch [00:29, 497.77batch/s]\u001b[A\n",
      "Epoch 1: 14723batch [00:30, 497.51batch/s]\u001b[A\n",
      "Epoch 1: 14773batch [00:30, 494.58batch/s]\u001b[A\n",
      "Epoch 1: 14823batch [00:30, 493.99batch/s]\u001b[A\n",
      "Epoch 1: 14873batch [00:30, 485.92batch/s]\u001b[A\n",
      "Epoch 1: 14923batch [00:30, 489.52batch/s]\u001b[A\n",
      "Epoch 1: 14973batch [00:30, 491.66batch/s]\u001b[A\n",
      "Epoch 1: 15023batch [00:30, 493.38batch/s]\u001b[A\n",
      "Epoch 1: 15073batch [00:30, 494.62batch/s]\u001b[A\n",
      "Epoch 1: 15123batch [00:30, 495.34batch/s]\u001b[A\n",
      "Epoch 1: 15173batch [00:30, 495.51batch/s]\u001b[A\n",
      "Epoch 1: 15223batch [00:31, 495.38batch/s]\u001b[A\n",
      "Epoch 1: 15273batch [00:31, 495.66batch/s]\u001b[A\n",
      "Epoch 1: 15323batch [00:31, 495.62batch/s]\u001b[A\n",
      "Epoch 1: 15373batch [00:31, 495.47batch/s]\u001b[A\n",
      "Epoch 1: 15423batch [00:31, 495.42batch/s]\u001b[A\n",
      "Epoch 1: 15473batch [00:31, 495.55batch/s]\u001b[A\n",
      "Epoch 1: 15523batch [00:31, 495.19batch/s]\u001b[A\n",
      "Epoch 1: 15573batch [00:31, 494.72batch/s]\u001b[A\n",
      "Epoch 1: 15623batch [00:31, 494.24batch/s]\u001b[A\n",
      "Epoch 1: 15673batch [00:31, 494.06batch/s]\u001b[A\n",
      "Epoch 1: 15723batch [00:32, 493.96batch/s]\u001b[A\n",
      "Epoch 1: 15773batch [00:32, 493.98batch/s]\u001b[A\n",
      "Epoch 1: 15823batch [00:32, 493.90batch/s]\u001b[A\n",
      "Epoch 1: 15873batch [00:32, 493.90batch/s]\u001b[A\n",
      "Epoch 1: 15923batch [00:32, 494.00batch/s]\u001b[A\n",
      "Epoch 1: 15973batch [00:32, 493.74batch/s]\u001b[A\n",
      "Epoch 1: 16023batch [00:32, 493.59batch/s]\u001b[A\n",
      "Epoch 1: 16073batch [00:32, 493.59batch/s]\u001b[A\n",
      "Epoch 1: 16123batch [00:32, 493.69batch/s]\u001b[A\n",
      "Epoch 1: 16173batch [00:32, 493.66batch/s]\u001b[A\n",
      "Epoch 1: 16223batch [00:33, 493.42batch/s]\u001b[A\n",
      "Epoch 1: 16273batch [00:33, 492.85batch/s]\u001b[A\n",
      "Epoch 1: 16323batch [00:33, 492.41batch/s]\u001b[A\n",
      "Epoch 1: 16373batch [00:33, 492.34batch/s]\u001b[A\n",
      "Epoch 1: 16423batch [00:33, 491.90batch/s]\u001b[A\n",
      "Epoch 1: 16473batch [00:33, 491.72batch/s]\u001b[A\n",
      "Epoch 1: 16523batch [00:33, 491.82batch/s]\u001b[A\n",
      "Epoch 1: 16573batch [00:33, 491.79batch/s]\u001b[A\n",
      "Epoch 1: 16623batch [00:33, 491.62batch/s]\u001b[A\n",
      "Epoch 1: 16673batch [00:33, 491.54batch/s]\u001b[A\n",
      "Epoch 1: 16723batch [00:34, 491.55batch/s]\u001b[A\n",
      "Epoch 1: 16773batch [00:34, 491.65batch/s]\u001b[A\n",
      "Epoch 1: 16823batch [00:34, 491.40batch/s]\u001b[A\n",
      "Epoch 1: 16873batch [00:34, 491.37batch/s]\u001b[A\n",
      "Epoch 1: 16923batch [00:34, 491.59batch/s]\u001b[A\n",
      "Epoch 1: 16973batch [00:34, 491.33batch/s]\u001b[A\n",
      "Epoch 1: 17023batch [00:34, 491.10batch/s]\u001b[A\n",
      "Epoch 1: 17073batch [00:34, 491.07batch/s]\u001b[A\n",
      "Epoch 1: 17123batch [00:34, 491.11batch/s]\u001b[A\n",
      "Epoch 1: 17173batch [00:34, 491.31batch/s]\u001b[A\n",
      "Epoch 1: 17223batch [00:35, 491.47batch/s]\u001b[A\n",
      "Epoch 1: 17273batch [00:35, 491.34batch/s]\u001b[A\n",
      "Epoch 1: 17323batch [00:35, 491.30batch/s]\u001b[A\n",
      "Epoch 1: 17373batch [00:35, 491.49batch/s]\u001b[A\n",
      "Epoch 1: 17423batch [00:35, 491.78batch/s]\u001b[A\n",
      "Epoch 1: 17473batch [00:35, 491.44batch/s]\u001b[A\n",
      "Epoch 1: 17523batch [00:35, 491.43batch/s]\u001b[A\n",
      "Epoch 1: 17573batch [00:35, 491.47batch/s]\u001b[A\n",
      "Epoch 1: 17623batch [00:35, 491.52batch/s]\u001b[A\n",
      "Epoch 1: 17673batch [00:36, 491.43batch/s]\u001b[A\n",
      "Epoch 1: 17723batch [00:36, 491.63batch/s]\u001b[A\n",
      "Epoch 1: 17773batch [00:36, 491.66batch/s]\u001b[A\n",
      "Epoch 1: 17823batch [00:36, 491.59batch/s]\u001b[A\n",
      "Epoch 1: 17873batch [00:36, 491.74batch/s]\u001b[A\n",
      "Epoch 1: 17923batch [00:36, 491.65batch/s]\u001b[A\n",
      "Epoch 1: 17973batch [00:36, 491.52batch/s]\u001b[A\n",
      "Epoch 1: 18023batch [00:36, 491.41batch/s]\u001b[A\n",
      "Epoch 1: 18073batch [00:36, 491.75batch/s]\u001b[A\n",
      "Epoch 1: 18123batch [00:36, 491.61batch/s]\u001b[A\n",
      "Epoch 1: 18173batch [00:37, 491.65batch/s]\u001b[A\n",
      "Epoch 1: 18223batch [00:37, 491.54batch/s]\u001b[A\n",
      "Epoch 1: 18273batch [00:37, 491.53batch/s]\u001b[A\n",
      "Epoch 1: 18323batch [00:37, 491.51batch/s]\u001b[A\n",
      "Epoch 1: 18373batch [00:37, 491.45batch/s]\u001b[A\n",
      "Epoch 1: 18423batch [00:37, 491.55batch/s]\u001b[A\n",
      "Epoch 1: 18473batch [00:37, 491.72batch/s]\u001b[A\n",
      "Epoch 1: 18523batch [00:37, 491.57batch/s]\u001b[A\n",
      "Epoch 1: 18573batch [00:37, 491.95batch/s]\u001b[A\n",
      "Epoch 1: 18623batch [00:37, 476.03batch/s]\u001b[A\n",
      "Epoch 1: 18673batch [00:38, 480.47batch/s]\u001b[A\n",
      "Epoch 1: 18723batch [00:38, 483.89batch/s]\u001b[A\n",
      "Epoch 1: 18773batch [00:38, 486.30batch/s]\u001b[A\n",
      "Epoch 1: 18823batch [00:38, 488.17batch/s]\u001b[A\n",
      "Epoch 1: 18873batch [00:38, 489.76batch/s]\u001b[A\n",
      "Epoch 1: 18923batch [00:38, 490.65batch/s]\u001b[A\n",
      "Epoch 1: 18973batch [00:38, 491.33batch/s]\u001b[A\n",
      "Epoch 1: 19023batch [00:38, 491.94batch/s]\u001b[A\n",
      "Epoch 1: 19073batch [00:38, 491.21batch/s]\u001b[A\n",
      "Epoch 1: 19123batch [00:38, 491.82batch/s]\u001b[A\n",
      "Epoch 1: 19173batch [00:39, 492.13batch/s]\u001b[A\n",
      "Epoch 1: 19223batch [00:39, 492.44batch/s]\u001b[A\n",
      "Epoch 1: 19273batch [00:39, 492.77batch/s]\u001b[A\n",
      "Epoch 1: 19323batch [00:39, 492.99batch/s]\u001b[A\n",
      "Epoch 1: 19373batch [00:39, 492.93batch/s]\u001b[A\n",
      "Epoch 1: 19423batch [00:39, 490.87batch/s]\u001b[A\n",
      "Epoch 1: 19473batch [00:39, 491.40batch/s]\u001b[A\n",
      "Epoch 1: 19523batch [00:39, 492.29batch/s]\u001b[A\n",
      "Epoch 1: 19573batch [00:39, 492.69batch/s]\u001b[A\n",
      "Epoch 1: 19623batch [00:39, 492.92batch/s]\u001b[A\n",
      "Epoch 1: 19673batch [00:40, 492.96batch/s]\u001b[A\n",
      "Epoch 1: 19723batch [00:40, 493.14batch/s]\u001b[A\n",
      "Epoch 1: 19773batch [00:40, 493.15batch/s]\u001b[A\n",
      "Epoch 1: 19823batch [00:40, 493.49batch/s]\u001b[A\n",
      "Epoch 1: 19873batch [00:40, 493.60batch/s]\u001b[A\n",
      "Epoch 1: 19923batch [00:40, 493.66batch/s]\u001b[A\n",
      "Epoch 1: 19973batch [00:40, 493.58batch/s]\u001b[A\n",
      "Epoch 1: 20023batch [00:40, 493.60batch/s]\u001b[A\n",
      "Epoch 1: 20073batch [00:40, 493.83batch/s]\u001b[A\n",
      "Epoch 1: 20123batch [00:40, 480.37batch/s]\u001b[A\n",
      "Epoch 1: 20173batch [00:41, 484.27batch/s]\u001b[A\n",
      "Epoch 1: 20223batch [00:41, 487.09batch/s]\u001b[A\n",
      "Epoch 1: 20273batch [00:41, 489.41batch/s]\u001b[A\n",
      "Epoch 1: 20323batch [00:41, 490.90batch/s]\u001b[A\n",
      "Epoch 1: 20373batch [00:41, 492.07batch/s]\u001b[A\n",
      "Epoch 1: 20423batch [00:41, 492.79batch/s]\u001b[A\n",
      "Epoch 1: 20473batch [00:41, 493.31batch/s]\u001b[A\n",
      "Epoch 1: 20523batch [00:41, 493.63batch/s]\u001b[A\n",
      "Epoch 1: 20573batch [00:41, 494.03batch/s]\u001b[A\n",
      "Epoch 1: 20623batch [00:42, 494.20batch/s]\u001b[A\n",
      "Epoch 1: 20673batch [00:42, 494.29batch/s]\u001b[A\n",
      "Epoch 1: 20723batch [00:42, 494.15batch/s]\u001b[A\n",
      "Epoch 1: 20773batch [00:42, 494.33batch/s]\u001b[A\n",
      "Epoch 1: 20823batch [00:42, 494.39batch/s]\u001b[A\n",
      "Epoch 1: 20873batch [00:42, 494.79batch/s]\u001b[A\n",
      "Epoch 1: 20923batch [00:42, 495.01batch/s]\u001b[A\n",
      "Epoch 1: 20973batch [00:42, 495.07batch/s]\u001b[A\n",
      "Epoch 1: 21023batch [00:42, 495.15batch/s]\u001b[A\n",
      "Epoch 1: 21073batch [00:42, 494.93batch/s]\u001b[A\n",
      "Epoch 1: 21123batch [00:43, 494.74batch/s]\u001b[A\n",
      "Epoch 1: 21173batch [00:43, 494.52batch/s]\u001b[A\n",
      "Epoch 1: 21223batch [00:43, 494.24batch/s]\u001b[A\n",
      "Epoch 1: 21273batch [00:43, 494.23batch/s]\u001b[A\n",
      "Epoch 1: 21323batch [00:43, 494.51batch/s]\u001b[A\n",
      "Epoch 1: 21373batch [00:43, 494.70batch/s]\u001b[A\n",
      "Epoch 1: 21423batch [00:43, 494.01batch/s]\u001b[A\n",
      "Epoch 1: 21473batch [00:43, 493.92batch/s]\u001b[A\n",
      "Epoch 1: 21523batch [00:43, 493.81batch/s]\u001b[A\n",
      "Epoch 1: 21573batch [00:43, 493.94batch/s]\u001b[A\n",
      "Epoch 1: 21623batch [00:44, 493.85batch/s]\u001b[A\n",
      "Epoch 1: 21673batch [00:44, 493.77batch/s]\u001b[A\n",
      "Epoch 1: 21723batch [00:44, 493.84batch/s]\u001b[A\n",
      "Epoch 1: 21773batch [00:44, 494.13batch/s]\u001b[A\n",
      "Epoch 1: 21823batch [00:44, 494.58batch/s]\u001b[A\n",
      "Epoch 1: 21873batch [00:44, 494.79batch/s]\u001b[A\n",
      "Epoch 1: 21923batch [00:44, 494.82batch/s]\u001b[A\n",
      "Epoch 1: 21973batch [00:44, 494.50batch/s]\u001b[A\n",
      "Epoch 1: 22023batch [00:44, 494.38batch/s]\u001b[A\n",
      "Epoch 1: 22073batch [00:44, 494.14batch/s]\u001b[A\n",
      "Epoch 1: 22123batch [00:45, 494.13batch/s]\u001b[A\n",
      "Epoch 1: 22173batch [00:45, 493.96batch/s]\u001b[A\n",
      "Epoch 1: 22223batch [00:45, 494.16batch/s]\u001b[A\n",
      "Epoch 1: 22273batch [00:45, 494.16batch/s]\u001b[A\n",
      "Epoch 1: 22323batch [00:45, 493.93batch/s]\u001b[A\n",
      "Epoch 1: 22373batch [00:45, 493.87batch/s]\u001b[A\n",
      "Epoch 1: 22423batch [00:45, 493.96batch/s]\u001b[A\n",
      "Epoch 1: 22473batch [00:45, 493.94batch/s]\u001b[A\n",
      "Epoch 1: 22523batch [00:45, 493.88batch/s]\u001b[A\n",
      "Epoch 1: 22573batch [00:45, 493.97batch/s]\u001b[A\n",
      "Epoch 1: 22623batch [00:46, 493.90batch/s]\u001b[A\n",
      "Epoch 1: 22673batch [00:46, 493.78batch/s]\u001b[A\n",
      "Epoch 1: 22723batch [00:46, 493.83batch/s]\u001b[A\n",
      "Epoch 1: 22773batch [00:46, 493.52batch/s]\u001b[A\n",
      "Epoch 1: 22823batch [00:46, 493.48batch/s]\u001b[A\n",
      "Epoch 1: 22873batch [00:46, 493.31batch/s]\u001b[A\n",
      "Epoch 1: 22923batch [00:46, 493.30batch/s]\u001b[A\n",
      "Epoch 1: 22973batch [00:46, 493.12batch/s]\u001b[A\n",
      "Epoch 1: 23023batch [00:46, 492.86batch/s]\u001b[A\n",
      "Epoch 1: 23073batch [00:46, 494.80batch/s]\u001b[A\n",
      "Epoch 1: 23123batch [00:47, 496.17batch/s]\u001b[A\n",
      "Epoch 1: 23174batch [00:47, 497.43batch/s]\u001b[A\n",
      "Epoch 1: 23225batch [00:47, 498.36batch/s]\u001b[A\n",
      "Epoch 1: 23276batch [00:47, 499.06batch/s]\u001b[A\n",
      "Epoch 1: 23326batch [00:47, 499.31batch/s]\u001b[A\n",
      "Epoch 1: 23376batch [00:47, 499.09batch/s]\u001b[A\n",
      "Epoch 1: 23426batch [00:47, 499.21batch/s]\u001b[A\n",
      "Epoch 1: 23476batch [00:47, 497.04batch/s]\u001b[A\n",
      "Epoch 1: 23526batch [00:47, 495.61batch/s]\u001b[A\n",
      "Epoch 1: 23576batch [00:47, 494.39batch/s]\u001b[A\n",
      "Epoch 1: 23626batch [00:48, 493.37batch/s]\u001b[A\n",
      "Epoch 1: 23676batch [00:48, 492.94batch/s]\u001b[A\n",
      "Epoch 1: 23726batch [00:48, 493.85batch/s]\u001b[A\n",
      "Epoch 1: 23776batch [00:48, 495.49batch/s]\u001b[A\n",
      "Epoch 1: 23826batch [00:48, 496.73batch/s]\u001b[A\n",
      "Epoch 1: 23876batch [00:48, 497.49batch/s]\u001b[A\n",
      "Epoch 1: 23926batch [00:48, 497.79batch/s]\u001b[A\n",
      "Epoch 1: 23977batch [00:48, 498.88batch/s]\u001b[A\n",
      "Epoch 1: 24027batch [00:48, 498.58batch/s]\u001b[A\n",
      "Epoch 1: 24077batch [00:48, 498.68batch/s]\u001b[A\n",
      "Epoch 1: 24127batch [00:49, 497.02batch/s]\u001b[A\n",
      "Epoch 1: 24177batch [00:49, 496.61batch/s]\u001b[A\n",
      "Epoch 1: 24228batch [00:49, 497.66batch/s]\u001b[A\n",
      "Epoch 1: 24278batch [00:49, 498.09batch/s]\u001b[A\n",
      "Epoch 1: 24328batch [00:49, 498.32batch/s]\u001b[A\n",
      "Epoch 1: 24378batch [00:49, 498.31batch/s]\u001b[A\n",
      "Epoch 1: 24428batch [00:49, 498.52batch/s]\u001b[A\n",
      "Epoch 1: 24478batch [00:49, 497.27batch/s]\u001b[A\n",
      "Epoch 1: 24528batch [00:49, 495.78batch/s]\u001b[A\n",
      "Epoch 1: 24578batch [00:49, 494.22batch/s]\u001b[A\n",
      "Epoch 1: 24628batch [00:50, 493.38batch/s]\u001b[A\n",
      "Epoch 1: 24678batch [00:50, 492.61batch/s]\u001b[A\n",
      "Epoch 1: 24728batch [00:50, 492.42batch/s]\u001b[A\n",
      "Epoch 1: 24778batch [00:50, 492.43batch/s]\u001b[A\n",
      "Epoch 1: 24828batch [00:50, 491.99batch/s]\u001b[A\n",
      "Epoch 1: 24878batch [00:50, 492.09batch/s]\u001b[A\n",
      "Epoch 1: 24928batch [00:50, 492.42batch/s]\u001b[A\n",
      "Epoch 1: 24978batch [00:50, 492.70batch/s]\u001b[A\n",
      "Epoch 1: 25028batch [00:50, 493.11batch/s]\u001b[A\n",
      "Epoch 1: 25078batch [00:51, 490.37batch/s]\u001b[A\n",
      "Epoch 1: 25128batch [00:51, 479.89batch/s]\u001b[A\n",
      "Epoch 1: 25178batch [00:51, 483.85batch/s]\u001b[A\n",
      "Epoch 1: 25228batch [00:51, 486.65batch/s]\u001b[A\n",
      "Epoch 1: 25278batch [00:51, 488.80batch/s]\u001b[A\n",
      "Epoch 1: 25328batch [00:51, 489.95batch/s]\u001b[A\n",
      "Epoch 1: 25378batch [00:51, 491.19batch/s]\u001b[A\n",
      "Epoch 1: 25428batch [00:51, 492.03batch/s]\u001b[A\n",
      "Epoch 1: 25478batch [00:51, 492.86batch/s]\u001b[A\n",
      "Epoch 1: 25528batch [00:51, 493.18batch/s]\u001b[A\n",
      "Epoch 1: 25578batch [00:52, 493.35batch/s]\u001b[A\n",
      "Epoch 1: 25628batch [00:52, 493.45batch/s]\u001b[A\n",
      "Epoch 1: 25678batch [00:52, 493.85batch/s]\u001b[A\n",
      "Epoch 1: 25728batch [00:52, 493.98batch/s]\u001b[A\n",
      "Epoch 1: 25778batch [00:52, 493.98batch/s]\u001b[A\n",
      "Epoch 1: 25828batch [00:52, 493.85batch/s]\u001b[A\n",
      "Epoch 1: 25878batch [00:52, 493.93batch/s]\u001b[A\n",
      "Epoch 1: 25928batch [00:52, 493.64batch/s]\u001b[A\n",
      "Epoch 1: 25978batch [00:52, 493.64batch/s]\u001b[A\n",
      "Epoch 1: 26028batch [00:52, 493.74batch/s]\u001b[A\n",
      "Epoch 1: 26078batch [00:53, 493.89batch/s]\u001b[A\n",
      "Epoch 1: 26128batch [00:53, 493.95batch/s]\u001b[A\n",
      "Epoch 1: 26178batch [00:53, 493.82batch/s]\u001b[A\n",
      "Epoch 1: 26228batch [00:53, 494.05batch/s]\u001b[A\n",
      "Epoch 1: 26278batch [00:53, 493.86batch/s]\u001b[A\n",
      "Epoch 1: 26328batch [00:53, 493.78batch/s]\u001b[A\n",
      "Epoch 1: 26378batch [00:53, 493.83batch/s]\u001b[A\n",
      "Epoch 1: 26428batch [00:53, 493.84batch/s]\u001b[A\n",
      "Epoch 1: 26478batch [00:53, 493.87batch/s]\u001b[A\n",
      "Epoch 1: 26528batch [00:53, 493.83batch/s]\u001b[A\n",
      "Epoch 1: 26578batch [00:54, 493.75batch/s]\u001b[A\n",
      "Epoch 1: 26628batch [00:54, 493.57batch/s]\u001b[A\n",
      "Epoch 1: 26678batch [00:54, 493.32batch/s]\u001b[A\n",
      "Epoch 1: 26728batch [00:54, 493.23batch/s]\u001b[A\n",
      "Epoch 1: 26778batch [00:54, 492.97batch/s]\u001b[A\n",
      "Epoch 1: 26828batch [00:54, 492.56batch/s]\u001b[A\n",
      "Epoch 1: 26878batch [00:54, 493.03batch/s]\u001b[A\n",
      "Epoch 1: 26928batch [00:54, 492.80batch/s]\u001b[A\n",
      "Epoch 1: 26978batch [00:54, 492.97batch/s]\u001b[A\n",
      "Epoch 1: 27028batch [00:54, 493.22batch/s]\u001b[A\n",
      "Epoch 1: 27078batch [00:55, 493.39batch/s]\u001b[A\n",
      "Epoch 1: 27128batch [00:55, 493.43batch/s]\u001b[A\n",
      "Epoch 1: 27178batch [00:55, 493.61batch/s]\u001b[A\n",
      "Epoch 1: 27228batch [00:55, 493.54batch/s]\u001b[A\n",
      "Epoch 1: 27278batch [00:55, 493.38batch/s]\u001b[A\n",
      "Epoch 1: 27328batch [00:55, 493.37batch/s]\u001b[A\n",
      "Epoch 1: 27378batch [00:55, 493.37batch/s]\u001b[A\n",
      "Epoch 1: 27428batch [00:55, 493.37batch/s]\u001b[A\n",
      "Epoch 1: 27478batch [00:55, 493.55batch/s]\u001b[A\n",
      "Epoch 1: 27528batch [00:55, 493.58batch/s]\u001b[A\n",
      "Epoch 1: 27578batch [00:56, 493.66batch/s]\u001b[A\n",
      "Epoch 1: 27628batch [00:56, 493.62batch/s]\u001b[A\n",
      "Epoch 1: 27678batch [00:56, 493.76batch/s]\u001b[A\n",
      "Epoch 1: 27728batch [00:56, 493.73batch/s]\u001b[A\n",
      "Epoch 1: 27778batch [00:56, 493.96batch/s]\u001b[A\n",
      "Epoch 1: 27828batch [00:56, 494.13batch/s]\u001b[A\n",
      "Epoch 1: 27878batch [00:56, 494.36batch/s]\u001b[A\n",
      "Epoch 1: 27928batch [00:56, 494.58batch/s]\u001b[A\n",
      "Epoch 1: 27978batch [00:56, 494.42batch/s]\u001b[A\n",
      "Epoch 1: 28028batch [00:56, 494.26batch/s]\u001b[A\n",
      "Epoch 1: 28078batch [00:57, 494.37batch/s]\u001b[A\n",
      "Epoch 1: 28128batch [00:57, 494.14batch/s]\u001b[A\n",
      "Epoch 1: 28178batch [00:57, 493.94batch/s]\u001b[A\n",
      "Epoch 1: 28228batch [00:57, 493.90batch/s]\u001b[A\n",
      "Epoch 1: 28278batch [00:57, 493.92batch/s]\u001b[A\n",
      "Epoch 1: 28328batch [00:57, 493.89batch/s]\u001b[A\n",
      "Epoch 1: 28378batch [00:57, 493.76batch/s]\u001b[A\n",
      "Epoch 1: 28428batch [00:57, 493.73batch/s]\u001b[A\n",
      "Epoch 1: 28478batch [00:57, 493.74batch/s]\u001b[A\n",
      "Epoch 1: 28528batch [00:58, 493.57batch/s]\u001b[A\n",
      "Epoch 1: 28578batch [00:58, 493.56batch/s]\u001b[A\n",
      "Epoch 1: 28628batch [00:58, 493.62batch/s]\u001b[A\n",
      "Epoch 1: 28678batch [00:58, 493.44batch/s]\u001b[A\n",
      "Epoch 1: 28728batch [00:58, 493.67batch/s]\u001b[A\n",
      "Epoch 1: 28778batch [00:58, 493.66batch/s]\u001b[A\n",
      "Epoch 1: 28828batch [00:58, 493.17batch/s]\u001b[A\n",
      "Epoch 1: 28878batch [00:58, 493.05batch/s]\u001b[A\n",
      "Epoch 1: 28928batch [00:58, 493.29batch/s]\u001b[A\n",
      "Epoch 1: 28978batch [00:58, 493.32batch/s]\u001b[A\n",
      "Epoch 1: 29028batch [00:59, 493.27batch/s]\u001b[A\n",
      "Epoch 1: 29078batch [00:59, 491.65batch/s]\u001b[A\n",
      "Epoch 1: 29128batch [00:59, 492.00batch/s]\u001b[A\n",
      "Epoch 1: 29178batch [00:59, 491.95batch/s]\u001b[A\n",
      "Epoch 1: 29228batch [00:59, 492.08batch/s]\u001b[A\n",
      "Epoch 1: 29278batch [00:59, 492.22batch/s]\u001b[A\n",
      "Epoch 1: 29328batch [00:59, 492.40batch/s]\u001b[A\n",
      "Epoch 1: 29378batch [00:59, 492.60batch/s]\u001b[A\n",
      "Epoch 1: 29428batch [00:59, 492.83batch/s]\u001b[A\n",
      "Epoch 1: 29478batch [00:59, 493.00batch/s]\u001b[A\n",
      "Epoch 1: 29528batch [01:00, 492.80batch/s]\u001b[A\n",
      "Epoch 1: 29578batch [01:00, 492.88batch/s]\u001b[A\n",
      "Epoch 1: 29628batch [01:00, 493.04batch/s]\u001b[A\n",
      "Epoch 1: 29678batch [01:00, 493.19batch/s]\u001b[A\n",
      "Epoch 1: 29728batch [01:00, 493.45batch/s]\u001b[A\n",
      "Epoch 1: 29778batch [01:00, 493.38batch/s]\u001b[A\n",
      "Epoch 1: 29828batch [01:00, 493.49batch/s]\u001b[A\n",
      "Epoch 1: 29878batch [01:00, 493.60batch/s]\u001b[A\n",
      "Epoch 1: 29928batch [01:00, 493.66batch/s]\u001b[A\n",
      "Epoch 1: 29978batch [01:00, 493.48batch/s]\u001b[A\n",
      "Epoch 1: 30028batch [01:01, 493.31batch/s]\u001b[A\n",
      "Epoch 1: 30078batch [01:01, 488.52batch/s]\u001b[A\n",
      "Epoch 1: 30127batch [01:01, 481.64batch/s]\u001b[A\n",
      "Epoch 1: 30177batch [01:01, 485.02batch/s]\u001b[A\n",
      "Epoch 1: 30227batch [01:01, 487.50batch/s]\u001b[A\n",
      "Epoch 1: 30277batch [01:01, 489.42batch/s]\u001b[A\n",
      "Epoch 1: 30327batch [01:01, 490.74batch/s]\u001b[A\n",
      "Epoch 1: 30377batch [01:01, 491.33batch/s]\u001b[A\n",
      "Epoch 1: 30427batch [01:01, 491.94batch/s]\u001b[A\n",
      "Epoch 1: 30477batch [01:01, 492.21batch/s]\u001b[A\n",
      "Epoch 1: 30527batch [01:02, 492.81batch/s]\u001b[A\n",
      "Epoch 1: 30577batch [01:02, 492.97batch/s]\u001b[A\n",
      "Epoch 1: 30627batch [01:02, 493.12batch/s]\u001b[A\n",
      "Epoch 1: 30677batch [01:02, 493.16batch/s]\u001b[A\n",
      "Epoch 1: 30727batch [01:02, 492.90batch/s]\u001b[A\n",
      "Epoch 1: 30777batch [01:02, 492.52batch/s]\u001b[A\n",
      "Epoch 1: 30827batch [01:02, 492.62batch/s]\u001b[A\n",
      "Epoch 1: 30877batch [01:02, 492.65batch/s]\u001b[A\n",
      "Epoch 1: 30927batch [01:02, 492.86batch/s]\u001b[A\n",
      "Epoch 1: 30977batch [01:02, 493.07batch/s]\u001b[A\n",
      "Epoch 1: 31027batch [01:03, 493.02batch/s]\u001b[A\n",
      "Epoch 1: 31077batch [01:03, 493.43batch/s]\u001b[A\n",
      "Epoch 1: 31127batch [01:03, 493.46batch/s]\u001b[A\n",
      "Epoch 1: 31177batch [01:03, 493.47batch/s]\u001b[A\n",
      "Epoch 1: 31227batch [01:03, 493.35batch/s]\u001b[A\n",
      "Epoch 1: 31277batch [01:03, 493.38batch/s]\u001b[A\n",
      "Epoch 1: 31327batch [01:03, 493.41batch/s]\u001b[A\n",
      "Epoch 1: 31377batch [01:03, 493.53batch/s]\u001b[A\n",
      "Epoch 1: 31427batch [01:03, 493.62batch/s]\u001b[A\n",
      "Epoch 1: 31477batch [01:03, 493.38batch/s]\u001b[A\n",
      "Epoch 1: 31527batch [01:04, 493.27batch/s]\u001b[A\n",
      "Epoch 1: 31577batch [01:04, 493.33batch/s]\u001b[A\n",
      "Epoch 1: 31627batch [01:04, 493.34batch/s]\u001b[A\n",
      "Epoch 1: 31677batch [01:04, 493.62batch/s]\u001b[A\n",
      "Epoch 1: 31727batch [01:04, 493.63batch/s]\u001b[A\n",
      "Epoch 1: 31777batch [01:04, 493.61batch/s]\u001b[A\n",
      "Epoch 1: 31827batch [01:04, 493.65batch/s]\u001b[A\n",
      "Epoch 1: 31877batch [01:04, 493.70batch/s]\u001b[A\n",
      "Epoch 1: 31927batch [01:04, 493.84batch/s]\u001b[A\n",
      "Epoch 1: 31977batch [01:05, 493.57batch/s]\u001b[A\n",
      "Epoch 1: 32027batch [01:05, 493.70batch/s]\u001b[A\n",
      "Epoch 1: 32077batch [01:05, 493.67batch/s]\u001b[A\n",
      "Epoch 1: 32127batch [01:05, 493.40batch/s]\u001b[A\n",
      "Epoch 1: 32177batch [01:05, 493.29batch/s]\u001b[A\n",
      "Epoch 1: 32227batch [01:05, 493.00batch/s]\u001b[A\n",
      "Epoch 1: 32277batch [01:05, 493.11batch/s]\u001b[A\n",
      "Epoch 1: 32327batch [01:05, 493.20batch/s]\u001b[A\n",
      "Epoch 1: 32377batch [01:05, 493.23batch/s]\u001b[A\n",
      "Epoch 1: 32427batch [01:05, 493.16batch/s]\u001b[A\n",
      "Epoch 1: 32477batch [01:06, 493.56batch/s]\u001b[A\n",
      "Epoch 1: 32527batch [01:06, 493.80batch/s]\u001b[A\n",
      "Epoch 1: 32577batch [01:06, 493.73batch/s]\u001b[A\n",
      "Epoch 1: 32627batch [01:06, 493.73batch/s]\u001b[A\n",
      "Epoch 1: 32677batch [01:06, 493.72batch/s]\u001b[A\n",
      "Epoch 1: 32727batch [01:06, 493.68batch/s]\u001b[A\n",
      "Epoch 1: 32777batch [01:06, 493.86batch/s]\u001b[A\n",
      "Epoch 1: 32827batch [01:06, 493.92batch/s]\u001b[A\n",
      "Epoch 1: 32877batch [01:06, 493.90batch/s]\u001b[A\n",
      "Epoch 1: 32927batch [01:06, 493.85batch/s]\u001b[A\n",
      "Epoch 1: 32977batch [01:07, 493.85batch/s]\u001b[A\n",
      "Epoch 1: 33027batch [01:07, 493.79batch/s]\u001b[A\n",
      "Epoch 1: 33077batch [01:07, 494.01batch/s]\u001b[A\n",
      "Epoch 1: 33127batch [01:07, 493.90batch/s]\u001b[A\n",
      "Epoch 1: 33177batch [01:07, 494.01batch/s]\u001b[A\n",
      "Epoch 1: 33227batch [01:07, 493.90batch/s]\u001b[A\n",
      "Epoch 1: 33277batch [01:07, 493.94batch/s]\u001b[A\n",
      "Epoch 1: 33327batch [01:07, 494.10batch/s]\u001b[A\n",
      "Epoch 1: 33377batch [01:07, 494.39batch/s]\u001b[A\n",
      "Epoch 1: 33427batch [01:07, 494.38batch/s]\u001b[A\n",
      "Epoch 1: 33477batch [01:08, 494.26batch/s]\u001b[A\n",
      "Epoch 1: 33527batch [01:08, 494.30batch/s]\u001b[A\n",
      "Epoch 1: 33577batch [01:08, 494.14batch/s]\u001b[A\n",
      "Epoch 1: 33627batch [01:08, 493.97batch/s]\u001b[A\n",
      "Epoch 1: 33677batch [01:08, 493.90batch/s]\u001b[A\n",
      "Epoch 1: 33727batch [01:08, 493.89batch/s]\u001b[A\n",
      "Epoch 1: 33777batch [01:08, 494.20batch/s]\u001b[A\n",
      "Epoch 1: 33827batch [01:08, 494.27batch/s]\u001b[A\n",
      "Epoch 1: 33877batch [01:08, 494.28batch/s]\u001b[A\n",
      "Epoch 1: 33927batch [01:08, 494.19batch/s]\u001b[A\n",
      "Epoch 1: 33977batch [01:09, 494.31batch/s]\u001b[A\n",
      "Epoch 1: 34027batch [01:09, 492.52batch/s]\u001b[A\n",
      "Epoch 1: 34077batch [01:09, 492.91batch/s]\u001b[A\n",
      "Epoch 1: 34127batch [01:09, 493.28batch/s]\u001b[A\n",
      "Epoch 1: 34177batch [01:09, 493.25batch/s]\u001b[A\n",
      "Epoch 1: 34227batch [01:09, 494.64batch/s]\u001b[A\n",
      "Epoch 1: 34277batch [01:09, 495.34batch/s]\u001b[A\n",
      "Epoch 1: 34328batch [01:09, 497.12batch/s]\u001b[A\n",
      "Epoch 1: 34379batch [01:09, 498.57batch/s]\u001b[A\n",
      "Epoch 1: 34430batch [01:09, 499.73batch/s]\u001b[A\n",
      "Epoch 1: 34480batch [01:10, 499.39batch/s]\u001b[A\n",
      "Epoch 1: 34530batch [01:10, 497.93batch/s]\u001b[A\n",
      "Epoch 1: 34580batch [01:10, 496.73batch/s]\u001b[A\n",
      "Epoch 1: 34630batch [01:10, 495.99batch/s]\u001b[A\n",
      "Epoch 1: 34680batch [01:10, 495.30batch/s]\u001b[A\n",
      "Epoch 1: 34730batch [01:10, 494.83batch/s]\u001b[A\n",
      "Epoch 1: 34780batch [01:10, 494.57batch/s]\u001b[A\n",
      "Epoch 1: 34830batch [01:10, 494.19batch/s]\u001b[A\n",
      "Epoch 1: 34880batch [01:10, 494.22batch/s]\u001b[A\n",
      "Epoch 1: 34930batch [01:10, 492.66batch/s]\u001b[A\n",
      "Epoch 1: 34980batch [01:11, 492.89batch/s]\u001b[A\n",
      "Epoch 1: 35030batch [01:11, 490.11batch/s]\u001b[A\n",
      "Epoch 1: 35080batch [01:11, 481.87batch/s]\u001b[A\n",
      "Epoch 1: 35130batch [01:11, 485.34batch/s]\u001b[A\n",
      "Epoch 1: 35180batch [01:11, 488.05batch/s]\u001b[A\n",
      "Epoch 1: 35230batch [01:11, 489.69batch/s]\u001b[A\n",
      "Epoch 1: 35280batch [01:11, 490.97batch/s]\u001b[A\n",
      "Epoch 1: 35330batch [01:11, 491.79batch/s]\u001b[A\n",
      "Epoch 1: 35380batch [01:11, 492.78batch/s]\u001b[A\n",
      "Epoch 1: 35430batch [01:12, 493.02batch/s]\u001b[A\n",
      "Epoch 1: 35480batch [01:12, 493.24batch/s]\u001b[A\n",
      "Epoch 1: 35530batch [01:12, 493.47batch/s]\u001b[A\n",
      "Epoch 1: 35580batch [01:12, 493.64batch/s]\u001b[A\n",
      "Epoch 1: 35630batch [01:12, 493.72batch/s]\u001b[A\n",
      "Epoch 1: 35680batch [01:12, 493.73batch/s]\u001b[A\n",
      "Epoch 1: 35730batch [01:12, 493.82batch/s]\u001b[A\n",
      "Epoch 1: 35780batch [01:12, 493.68batch/s]\u001b[A\n",
      "Epoch 1: 35830batch [01:12, 493.90batch/s]\u001b[A\n",
      "Epoch 1: 35880batch [01:12, 493.82batch/s]\u001b[A\n",
      "Epoch 1: 35930batch [01:13, 493.80batch/s]\u001b[A\n",
      "Epoch 1: 35980batch [01:13, 493.87batch/s]\u001b[A\n",
      "Epoch 1: 36030batch [01:13, 494.04batch/s]\u001b[A\n",
      "Epoch 1: 36080batch [01:13, 493.98batch/s]\u001b[A\n",
      "Epoch 1: 36130batch [01:13, 493.87batch/s]\u001b[A\n",
      "Epoch 1: 36180batch [01:13, 493.90batch/s]\u001b[A\n",
      "Epoch 1: 36230batch [01:13, 494.15batch/s]\u001b[A\n",
      "Epoch 1: 36281batch [01:13, 496.03batch/s]\u001b[A\n",
      "Epoch 1: 36332batch [01:13, 497.33batch/s]\u001b[A\n",
      "Epoch 1: 36383batch [01:13, 498.27batch/s]\u001b[A\n",
      "Epoch 1: 36434batch [01:14, 499.10batch/s]\u001b[A\n",
      "Epoch 1: 36484batch [01:14, 498.67batch/s]\u001b[A\n",
      "Epoch 1: 36534batch [01:14, 498.24batch/s]\u001b[A\n",
      "Epoch 1: 36585batch [01:14, 498.83batch/s]\u001b[A\n",
      "Epoch 1: 36635batch [01:14, 498.80batch/s]\u001b[A\n",
      "Epoch 1: 36686batch [01:14, 499.35batch/s]\u001b[A\n",
      "Epoch 1: 36736batch [01:14, 499.03batch/s]\u001b[A\n",
      "Epoch 1: 36786batch [01:14, 497.45batch/s]\u001b[A\n",
      "Epoch 1: 36836batch [01:14, 496.22batch/s]\u001b[A\n",
      "Epoch 1: 36886batch [01:14, 495.31batch/s]\u001b[A\n",
      "Epoch 1: 36936batch [01:15, 494.84batch/s]\u001b[A\n",
      "Epoch 1: 36986batch [01:15, 494.66batch/s]\u001b[A\n",
      "Epoch 1: 37036batch [01:15, 494.27batch/s]\u001b[A\n",
      "Epoch 1: 37086batch [01:15, 494.21batch/s]\u001b[A\n",
      "Epoch 1: 37136batch [01:15, 494.31batch/s]\u001b[A\n",
      "Epoch 1: 37186batch [01:15, 494.32batch/s]\u001b[A\n",
      "Epoch 1: 37236batch [01:15, 494.35batch/s]\u001b[A\n",
      "Epoch 1: 37286batch [01:15, 494.51batch/s]\u001b[A\n",
      "Epoch 1: 37336batch [01:15, 494.85batch/s]\u001b[A\n",
      "Epoch 1: 37386batch [01:15, 494.92batch/s]\u001b[A\n",
      "Epoch 1: 37436batch [01:16, 495.20batch/s]\u001b[A\n",
      "Epoch 1: 37486batch [01:16, 495.09batch/s]\u001b[A\n",
      "Epoch 1: 37536batch [01:16, 495.44batch/s]\u001b[A\n",
      "Epoch 1: 37586batch [01:16, 495.34batch/s]\u001b[A\n",
      "Epoch 1: 37636batch [01:16, 495.08batch/s]\u001b[A\n",
      "Epoch 1: 37686batch [01:16, 494.94batch/s]\u001b[A\n",
      "Epoch 1: 37736batch [01:16, 494.63batch/s]\u001b[A\n",
      "Epoch 1: 37786batch [01:16, 494.66batch/s]\u001b[A\n",
      "Epoch 1: 37836batch [01:16, 494.98batch/s]\u001b[A\n",
      "Epoch 1: 37886batch [01:16, 495.24batch/s]\u001b[A\n",
      "Epoch 1: 37936batch [01:17, 495.50batch/s]\u001b[A\n",
      "Epoch 1: 37986batch [01:17, 495.52batch/s]\u001b[A\n",
      "Epoch 1: 38036batch [01:17, 495.68batch/s]\u001b[A\n",
      "Epoch 1: 38086batch [01:17, 495.81batch/s]\u001b[A\n",
      "Epoch 1: 38136batch [01:17, 495.74batch/s]\u001b[A\n",
      "Epoch 1: 38186batch [01:17, 495.66batch/s]\u001b[A\n",
      "Epoch 1: 38236batch [01:17, 495.77batch/s]\u001b[A\n",
      "Epoch 1: 38286batch [01:17, 495.87batch/s]\u001b[A\n",
      "Epoch 1: 38336batch [01:17, 495.78batch/s]\u001b[A\n",
      "Epoch 1: 38386batch [01:17, 495.65batch/s]\u001b[A\n",
      "Epoch 1: 38436batch [01:18, 495.55batch/s]\u001b[A\n",
      "Epoch 1: 38486batch [01:18, 495.30batch/s]\u001b[A\n",
      "Epoch 1: 38536batch [01:18, 495.23batch/s]\u001b[A\n",
      "Epoch 1: 38586batch [01:18, 495.11batch/s]\u001b[A\n",
      "Epoch 1: 38636batch [01:18, 495.27batch/s]\u001b[A\n",
      "Epoch 1: 38686batch [01:18, 495.36batch/s]\u001b[A\n",
      "Epoch 1: 38736batch [01:18, 495.55batch/s]\u001b[A\n",
      "Epoch 1: 38786batch [01:18, 495.82batch/s]\u001b[A\n",
      "Epoch 1: 38836batch [01:18, 495.57batch/s]\u001b[A\n",
      "Epoch 1: 38886batch [01:18, 495.67batch/s]\u001b[A\n",
      "Epoch 1: 38936batch [01:19, 495.55batch/s]\u001b[A\n",
      "Epoch 1: 38986batch [01:19, 495.12batch/s]\u001b[A\n",
      "Epoch 1: 39036batch [01:19, 493.59batch/s]\u001b[A\n",
      "Epoch 1: 39086batch [01:19, 493.87batch/s]\u001b[A\n",
      "Epoch 1: 39136batch [01:19, 494.03batch/s]\u001b[A\n",
      "Epoch 1: 39186batch [01:19, 494.21batch/s]\u001b[A\n",
      "Epoch 1: 39236batch [01:19, 494.21batch/s]\u001b[A\n",
      "Epoch 1: 39286batch [01:19, 493.83batch/s]\u001b[A\n",
      "Epoch 1: 39336batch [01:19, 493.95batch/s]\u001b[A\n",
      "Epoch 1: 39386batch [01:19, 493.84batch/s]\u001b[A\n",
      "Epoch 1: 39436batch [01:20, 493.96batch/s]\u001b[A\n",
      "Epoch 1: 39486batch [01:20, 493.99batch/s]\u001b[A\n",
      "Epoch 1: 39536batch [01:20, 493.99batch/s]\u001b[A\n",
      "Epoch 1: 39586batch [01:20, 494.06batch/s]\u001b[A\n",
      "Epoch 1: 39636batch [01:20, 494.16batch/s]\u001b[A\n",
      "Epoch 1: 39686batch [01:20, 494.03batch/s]\u001b[A\n",
      "Epoch 1: 39736batch [01:20, 493.98batch/s]\u001b[A\n",
      "Epoch 1: 39786batch [01:20, 494.00batch/s]\u001b[A\n",
      "Epoch 1: 39836batch [01:20, 494.10batch/s]\u001b[A\n",
      "Epoch 1: 39886batch [01:21, 493.52batch/s]\u001b[A\n",
      "Epoch 1: 39936batch [01:21, 492.99batch/s]\u001b[A\n",
      "Epoch 1: 39986batch [01:21, 491.62batch/s]\u001b[A\n",
      "Epoch 1: 40036batch [01:21, 490.79batch/s]\u001b[A\n",
      "Epoch 1: 40086batch [01:21, 482.43batch/s]\u001b[A\n",
      "Epoch 1: 40136batch [01:21, 486.01batch/s]\u001b[A\n",
      "Epoch 1: 40186batch [01:21, 487.90batch/s]\u001b[A\n",
      "Epoch 1: 40236batch [01:21, 489.57batch/s]\u001b[A\n",
      "Epoch 1: 40286batch [01:21, 490.65batch/s]\u001b[A\n",
      "Epoch 1: 40336batch [01:21, 491.31batch/s]\u001b[A\n",
      "Epoch 1: 40386batch [01:22, 491.86batch/s]\u001b[A\n",
      "Epoch 1: 40436batch [01:22, 491.99batch/s]\u001b[A\n",
      "Epoch 1: 40486batch [01:22, 492.09batch/s]\u001b[A\n",
      "Epoch 1: 40536batch [01:22, 492.23batch/s]\u001b[A\n",
      "Epoch 1: 40586batch [01:22, 492.31batch/s]\u001b[A\n",
      "Epoch 1: 40636batch [01:22, 492.46batch/s]\u001b[A\n",
      "Epoch 1: 40686batch [01:22, 492.88batch/s]\u001b[A\n",
      "Epoch 1: 40736batch [01:22, 492.85batch/s]\u001b[A\n",
      "Epoch 1: 40786batch [01:22, 493.04batch/s]\u001b[A\n",
      "Epoch 1: 40836batch [01:22, 493.27batch/s]\u001b[A\n",
      "Epoch 1: 40886batch [01:23, 493.14batch/s]\u001b[A\n",
      "Epoch 1: 40936batch [01:23, 493.28batch/s]\u001b[A\n",
      "Epoch 1: 40986batch [01:23, 493.24batch/s]\u001b[A\n",
      "Epoch 1: 41036batch [01:23, 493.32batch/s]\u001b[A\n",
      "Epoch 1: 41086batch [01:23, 493.29batch/s]\u001b[A\n",
      "Epoch 1: 41136batch [01:23, 493.42batch/s]\u001b[A\n",
      "Epoch 1: 41186batch [01:23, 493.38batch/s]\u001b[A\n",
      "Epoch 1: 41236batch [01:23, 493.66batch/s]\u001b[A\n",
      "Epoch 1: 41286batch [01:23, 493.77batch/s]\u001b[A\n",
      "Epoch 1: 41336batch [01:23, 493.19batch/s]\u001b[A\n",
      "Epoch 1: 41386batch [01:24, 492.95batch/s]\u001b[A\n",
      "Epoch 1: 41436batch [01:24, 492.67batch/s]\u001b[A\n",
      "Epoch 1: 41486batch [01:24, 492.30batch/s]\u001b[A\n",
      "Epoch 1: 41536batch [01:24, 492.50batch/s]\u001b[A\n",
      "Epoch 1: 41586batch [01:24, 491.69batch/s]\u001b[A\n",
      "Epoch 1: 41637batch [01:24, 494.22batch/s]\u001b[A\n",
      "Epoch 1: 41687batch [01:24, 495.48batch/s]\u001b[A\n",
      "Epoch 1: 41737batch [01:24, 495.88batch/s]\u001b[A\n",
      "Epoch 1: 41787batch [01:24, 497.09batch/s]\u001b[A\n",
      "Epoch 1: 41837batch [01:24, 497.93batch/s]\u001b[A\n",
      "Epoch 1: 41887batch [01:25, 496.52batch/s]\u001b[A\n",
      "Epoch 1: 41937batch [01:25, 495.73batch/s]\u001b[A\n",
      "Epoch 1: 41987batch [01:25, 495.22batch/s]\u001b[A\n",
      "Epoch 1: 42037batch [01:25, 494.56batch/s]\u001b[A\n",
      "Epoch 1: 42087batch [01:25, 493.99batch/s]\u001b[A\n",
      "Epoch 1: 42137batch [01:25, 493.49batch/s]\u001b[A\n",
      "Epoch 1: 42187batch [01:25, 492.99batch/s]\u001b[A\n",
      "Epoch 1: 42237batch [01:25, 492.48batch/s]\u001b[A\n",
      "Epoch 1: 42287batch [01:25, 492.52batch/s]\u001b[A\n",
      "Epoch 1: 42337batch [01:25, 492.44batch/s]\u001b[A\n",
      "Epoch 1: 42387batch [01:26, 492.20batch/s]\u001b[A\n",
      "Epoch 1: 42437batch [01:26, 492.34batch/s]\u001b[A\n",
      "Epoch 1: 42487batch [01:26, 492.65batch/s]\u001b[A\n",
      "Epoch 1: 42537batch [01:26, 492.74batch/s]\u001b[A\n",
      "Epoch 1: 42587batch [01:26, 492.89batch/s]\u001b[A\n",
      "Epoch 1: 42637batch [01:26, 492.48batch/s]\u001b[A\n",
      "Epoch 1: 42687batch [01:26, 492.56batch/s]\u001b[A\n",
      "Epoch 1: 42737batch [01:26, 492.44batch/s]\u001b[A\n",
      "Epoch 1: 42787batch [01:26, 492.76batch/s]\u001b[A\n",
      "Epoch 1: 42837batch [01:26, 492.63batch/s]\u001b[A\n",
      "Epoch 1: 42887batch [01:27, 492.88batch/s]\u001b[A\n",
      "Epoch 1: 42937batch [01:27, 493.09batch/s]\u001b[A\n",
      "Epoch 1: 42987batch [01:27, 493.16batch/s]\u001b[A\n",
      "Epoch 1: 43037batch [01:27, 492.96batch/s]\u001b[A\n",
      "Epoch 1: 43087batch [01:27, 493.32batch/s]\u001b[A\n",
      "Epoch 1: 43137batch [01:27, 493.40batch/s]\u001b[A\n",
      "Epoch 1: 43187batch [01:27, 493.43batch/s]\u001b[A\n",
      "Epoch 1: 43237batch [01:27, 494.71batch/s]\u001b[A\n",
      "Epoch 1: 43288batch [01:27, 496.48batch/s]\u001b[A\n",
      "Epoch 1: 43339batch [01:28, 497.69batch/s]\u001b[A\n",
      "Epoch 1: 43390batch [01:28, 499.16batch/s]\u001b[A\n",
      "Epoch 1: 43441batch [01:28, 499.95batch/s]\u001b[A\n",
      "Epoch 1: 43492batch [01:28, 500.54batch/s]\u001b[A\n",
      "Epoch 1: 43543batch [01:28, 500.63batch/s]\u001b[A\n",
      "Epoch 1: 43594batch [01:28, 500.67batch/s]\u001b[A\n",
      "Epoch 1: 43645batch [01:28, 500.34batch/s]\u001b[A\n",
      "Epoch 1: 43696batch [01:28, 499.77batch/s]\u001b[A\n",
      "Epoch 1: 43746batch [01:28, 497.94batch/s]\u001b[A\n",
      "Epoch 1: 43796batch [01:28, 496.73batch/s]\u001b[A\n",
      "Epoch 1: 43846batch [01:29, 495.89batch/s]\u001b[A\n",
      "Epoch 1: 43896batch [01:29, 495.21batch/s]\u001b[A\n",
      "Epoch 1: 43946batch [01:29, 494.85batch/s]\u001b[A\n",
      "Epoch 1: 43996batch [01:29, 494.72batch/s]\u001b[A\n",
      "Epoch 1: 44046batch [01:29, 492.77batch/s]\u001b[A\n",
      "Epoch 1: 44096batch [01:29, 492.99batch/s]\u001b[A\n",
      "Epoch 1: 44146batch [01:29, 493.20batch/s]\u001b[A\n",
      "Epoch 1: 44196batch [01:29, 493.45batch/s]\u001b[A\n",
      "Epoch 1: 44246batch [01:29, 493.51batch/s]\u001b[A\n",
      "Epoch 1: 44296batch [01:29, 493.42batch/s]\u001b[A\n",
      "Epoch 1: 44346batch [01:30, 493.45batch/s]\u001b[A\n",
      "Epoch 1: 44396batch [01:30, 493.39batch/s]\u001b[A\n",
      "Epoch 1: 44446batch [01:30, 493.57batch/s]\u001b[A\n",
      "Epoch 1: 44496batch [01:30, 494.02batch/s]\u001b[A\n",
      "Epoch 1: 44546batch [01:30, 494.15batch/s]\u001b[A\n",
      "Epoch 1: 44596batch [01:30, 494.26batch/s]\u001b[A\n",
      "Epoch 1: 44646batch [01:30, 494.27batch/s]\u001b[A\n",
      "Epoch 1: 44696batch [01:30, 494.30batch/s]\u001b[A\n",
      "Epoch 1: 44746batch [01:30, 494.24batch/s]\u001b[A\n",
      "Epoch 1: 44796batch [01:30, 494.21batch/s]\u001b[A\n",
      "Epoch 1: 44846batch [01:31, 493.88batch/s]\u001b[A\n",
      "Epoch 1: 44896batch [01:31, 493.83batch/s]\u001b[A\n",
      "Epoch 1: 44946batch [01:31, 490.98batch/s]\u001b[A\n",
      "Epoch 1: 44996batch [01:31, 490.42batch/s]\u001b[A\n",
      "Epoch 1: 45046batch [01:31, 481.80batch/s]\u001b[A\n",
      "Epoch 1: 45096batch [01:31, 485.05batch/s]\u001b[A\n",
      "Epoch 1: 45146batch [01:31, 487.48batch/s]\u001b[A\n",
      "Epoch 1: 45196batch [01:31, 489.13batch/s]\u001b[A\n",
      "Epoch 1: 45246batch [01:31, 490.51batch/s]\u001b[A\n",
      "Epoch 1: 45296batch [01:31, 491.68batch/s]\u001b[A\n",
      "Epoch 1: 45346batch [01:32, 492.17batch/s]\u001b[A\n",
      "Epoch 1: 45396batch [01:32, 492.80batch/s]\u001b[A\n",
      "Epoch 1: 45446batch [01:32, 493.28batch/s]\u001b[A\n",
      "Epoch 1: 45496batch [01:32, 493.44batch/s]\u001b[A\n",
      "Epoch 1: 45546batch [01:32, 493.63batch/s]\u001b[A\n",
      "Epoch 1: 45596batch [01:32, 493.76batch/s]\u001b[A\n",
      "Epoch 1: 45646batch [01:32, 493.95batch/s]\u001b[A\n",
      "Epoch 1: 45696batch [01:32, 493.88batch/s]\u001b[A\n",
      "Epoch 1: 45746batch [01:32, 493.87batch/s]\u001b[A\n",
      "Epoch 1: 45796batch [01:32, 493.85batch/s]\u001b[A\n",
      "Epoch 1: 45846batch [01:33, 493.67batch/s]\u001b[A\n",
      "Epoch 1: 45896batch [01:33, 493.83batch/s]\u001b[A\n",
      "Epoch 1: 45946batch [01:33, 493.87batch/s]\u001b[A\n",
      "Epoch 1: 45996batch [01:33, 493.84batch/s]\u001b[A\n",
      "Epoch 1: 46046batch [01:33, 494.07batch/s]\u001b[A\n",
      "Epoch 1: 46096batch [01:33, 494.23batch/s]\u001b[A\n",
      "Epoch 1: 46146batch [01:33, 494.22batch/s]\u001b[A\n",
      "Epoch 1: 46196batch [01:33, 494.00batch/s]\u001b[A\n",
      "Epoch 1: 46246batch [01:33, 493.85batch/s]\u001b[A\n",
      "Epoch 1: 46296batch [01:33, 493.94batch/s]\u001b[A\n",
      "Epoch 1: 46346batch [01:34, 493.93batch/s]\u001b[A\n",
      "Epoch 1: 46396batch [01:34, 493.83batch/s]\u001b[A\n",
      "Epoch 1: 46446batch [01:34, 493.55batch/s]\u001b[A\n",
      "Epoch 1: 46496batch [01:34, 493.64batch/s]\u001b[A\n",
      "Epoch 1: 46546batch [01:34, 493.85batch/s]\u001b[A\n",
      "Epoch 1: 46596batch [01:34, 493.85batch/s]\u001b[A\n",
      "Epoch 1: 46646batch [01:34, 493.73batch/s]\u001b[A\n",
      "Epoch 1: 46696batch [01:34, 493.70batch/s]\u001b[A\n",
      "Epoch 1: 46746batch [01:34, 493.69batch/s]\u001b[A\n",
      "Epoch 1: 46796batch [01:35, 493.80batch/s]\u001b[A\n",
      "Epoch 1: 46846batch [01:35, 493.89batch/s]\u001b[A\n",
      "Epoch 1: 46896batch [01:35, 493.80batch/s]\u001b[A\n",
      "Epoch 1: 46946batch [01:35, 494.01batch/s]\u001b[A\n",
      "Epoch 1: 46996batch [01:35, 493.97batch/s]\u001b[A\n",
      "Epoch 1: 47046batch [01:35, 493.77batch/s]\u001b[A\n",
      "Epoch 1: 47096batch [01:35, 493.73batch/s]\u001b[A\n",
      "Epoch 1: 47146batch [01:35, 493.60batch/s]\u001b[A\n",
      "Epoch 1: 47196batch [01:35, 493.35batch/s]\u001b[A\n",
      "Epoch 1: 47246batch [01:35, 492.96batch/s]\u001b[A\n",
      "Epoch 1: 47296batch [01:36, 492.79batch/s]\u001b[A\n",
      "Epoch 1: 47346batch [01:36, 493.06batch/s]\u001b[A\n",
      "Epoch 1: 47396batch [01:36, 493.21batch/s]\u001b[A\n",
      "Epoch 1: 47446batch [01:36, 493.55batch/s]\u001b[A\n",
      "Epoch 1: 47496batch [01:36, 493.62batch/s]\u001b[A\n",
      "Epoch 1: 47546batch [01:36, 493.70batch/s]\u001b[A\n",
      "Epoch 1: 47596batch [01:36, 493.71batch/s]\u001b[A\n",
      "Epoch 1: 47646batch [01:36, 493.75batch/s]\u001b[A\n",
      "Epoch 1: 47696batch [01:36, 493.69batch/s]\u001b[A\n",
      "Epoch 1: 47746batch [01:36, 493.74batch/s]\u001b[A\n",
      "Epoch 1: 47796batch [01:37, 493.69batch/s]\u001b[A\n",
      "Epoch 1: 47846batch [01:37, 493.69batch/s]\u001b[A\n",
      "Epoch 1: 47896batch [01:37, 493.83batch/s]\u001b[A\n",
      "Epoch 1: 47946batch [01:37, 493.81batch/s]\u001b[A\n",
      "Epoch 1: 47996batch [01:37, 493.95batch/s]\u001b[A\n",
      "Epoch 1: 48046batch [01:37, 493.70batch/s]\u001b[A\n",
      "Epoch 1: 48096batch [01:37, 493.68batch/s]\u001b[A\n",
      "Epoch 1: 48146batch [01:37, 493.58batch/s]\u001b[A\n",
      "Epoch 1: 48196batch [01:37, 493.83batch/s]\u001b[A\n",
      "Epoch 1: 48246batch [01:37, 493.84batch/s]\u001b[A\n",
      "Epoch 1: 48296batch [01:38, 493.53batch/s]\u001b[A\n",
      "Epoch 1: 48346batch [01:38, 493.58batch/s]\u001b[A\n",
      "Epoch 1: 48396batch [01:38, 493.77batch/s]\u001b[A\n",
      "Epoch 1: 48446batch [01:38, 493.73batch/s]\u001b[A\n",
      "Epoch 1: 48496batch [01:38, 493.76batch/s]\u001b[A\n",
      "Epoch 1: 48546batch [01:38, 493.88batch/s]\u001b[A\n",
      "Epoch 1: 48596batch [01:38, 493.52batch/s]\u001b[A\n",
      "Epoch 1: 48646batch [01:38, 493.80batch/s]\u001b[A\n",
      "Epoch 1: 48696batch [01:38, 493.84batch/s]\u001b[A\n",
      "Epoch 1: 48746batch [01:38, 493.64batch/s]\u001b[A\n",
      "Epoch 1: 48796batch [01:39, 493.58batch/s]\u001b[A\n",
      "Epoch 1: 48846batch [01:39, 493.70batch/s]\u001b[A\n",
      "Epoch 1: 48896batch [01:39, 487.79batch/s]\u001b[A\n",
      "Epoch 1: 48945batch [01:39, 479.94batch/s]\u001b[A\n",
      "Epoch 1: 48995batch [01:39, 483.30batch/s]\u001b[A\n",
      "Epoch 1: 49045batch [01:39, 486.95batch/s]\u001b[A\n",
      "Epoch 1: 49095batch [01:39, 489.04batch/s]\u001b[A\n",
      "Epoch 1: 49145batch [01:39, 490.35batch/s]\u001b[A\n",
      "Epoch 1: 49195batch [01:39, 491.57batch/s]\u001b[A\n",
      "Epoch 1: 49245batch [01:39, 492.14batch/s]\u001b[A\n",
      "Epoch 1: 49295batch [01:40, 492.45batch/s]\u001b[A\n",
      "Epoch 1: 49345batch [01:40, 492.67batch/s]\u001b[A\n",
      "Epoch 1: 49395batch [01:40, 492.96batch/s]\u001b[A\n",
      "Epoch 1: 49445batch [01:40, 493.22batch/s]\u001b[A\n",
      "Epoch 1: 49495batch [01:40, 493.67batch/s]\u001b[A\n",
      "Epoch 1: 49545batch [01:40, 493.61batch/s]\u001b[A\n",
      "Epoch 1: 49595batch [01:40, 493.58batch/s]\u001b[A\n",
      "Epoch 1: 49645batch [01:40, 493.11batch/s]\u001b[A\n",
      "Epoch 1: 49695batch [01:40, 493.04batch/s]\u001b[A\n",
      "Epoch 1: 49745batch [01:40, 491.19batch/s]\u001b[A\n",
      "Epoch 1: 49795batch [01:41, 491.75batch/s]\u001b[A\n",
      "Epoch 1: 49845batch [01:41, 492.36batch/s]\u001b[A\n",
      "Epoch 1: 49895batch [01:41, 492.59batch/s]\u001b[A\n",
      "Epoch 1: 49945batch [01:41, 489.75batch/s]\u001b[A\n",
      "Epoch 1: 49994batch [01:41, 481.48batch/s]\u001b[A\n",
      "Epoch 1: 50044batch [01:41, 484.69batch/s]\u001b[A\n",
      "Epoch 1: 50094batch [01:41, 487.11batch/s]\u001b[A\n",
      "Epoch 1: 50144batch [01:41, 489.08batch/s]\u001b[A\n",
      "Epoch 1: 50194batch [01:41, 490.32batch/s]\u001b[A\n",
      "Epoch 1: 50244batch [01:42, 491.19batch/s]\u001b[A\n",
      "Epoch 1: 50294batch [01:42, 491.50batch/s]\u001b[A\n",
      "Epoch 1: 50344batch [01:42, 491.83batch/s]\u001b[A\n",
      "Epoch 1: 50394batch [01:42, 491.90batch/s]\u001b[A\n",
      "Epoch 1: 50444batch [01:42, 492.13batch/s]\u001b[A\n",
      "Epoch 1: 50494batch [01:42, 492.01batch/s]\u001b[A\n",
      "Epoch 1: 50544batch [01:42, 491.99batch/s]\u001b[A\n",
      "Epoch 1: 50594batch [01:42, 492.12batch/s]\u001b[A\n",
      "Epoch 1: 50644batch [01:42, 492.02batch/s]\u001b[A\n",
      "Epoch 1: 50694batch [01:42, 492.08batch/s]\u001b[A\n",
      "Epoch 1: 50744batch [01:43, 492.10batch/s]\u001b[A\n",
      "Epoch 1: 50794batch [01:43, 491.99batch/s]\u001b[A\n",
      "Epoch 1: 50844batch [01:43, 492.23batch/s]\u001b[A\n",
      "Epoch 1: 50894batch [01:43, 492.00batch/s]\u001b[A\n",
      "Epoch 1: 50944batch [01:43, 491.99batch/s]\u001b[A\n",
      "Epoch 1: 50994batch [01:43, 492.21batch/s]\u001b[A\n",
      "Epoch 1: 51044batch [01:43, 492.05batch/s]\u001b[A\n",
      "Epoch 1: 51094batch [01:43, 492.16batch/s]\u001b[A\n",
      "Epoch 1: 51144batch [01:43, 492.59batch/s]\u001b[A\n",
      "Epoch 1: 51194batch [01:43, 492.86batch/s]\u001b[A\n",
      "Epoch 1: 51244batch [01:44, 493.13batch/s]\u001b[A\n",
      "Epoch 1: 51294batch [01:44, 493.15batch/s]\u001b[A\n",
      "Epoch 1: 51344batch [01:44, 493.17batch/s]\u001b[A\n",
      "Epoch 1: 51394batch [01:44, 493.17batch/s]\u001b[A\n",
      "Epoch 1: 51444batch [01:44, 493.44batch/s]\u001b[A\n",
      "Epoch 1: 51494batch [01:44, 493.29batch/s]\u001b[A\n",
      "Epoch 1: 51544batch [01:44, 493.22batch/s]\u001b[A\n",
      "Epoch 1: 51594batch [01:44, 493.26batch/s]\u001b[A\n",
      "Epoch 1: 51644batch [01:44, 493.31batch/s]\u001b[A\n",
      "Epoch 1: 51694batch [01:44, 493.11batch/s]\u001b[A\n",
      "Epoch 1: 51744batch [01:45, 493.25batch/s]\u001b[A\n",
      "Epoch 1: 51794batch [01:45, 493.31batch/s]\u001b[A\n",
      "Epoch 1: 51844batch [01:45, 492.91batch/s]\u001b[A\n",
      "Epoch 1: 51894batch [01:45, 492.12batch/s]\u001b[A\n",
      "Epoch 1: 51944batch [01:45, 492.12batch/s]\u001b[A\n",
      "Epoch 1: 51994batch [01:45, 492.12batch/s]\u001b[A\n",
      "Epoch 1: 52044batch [01:45, 491.91batch/s]\u001b[A\n",
      "Epoch 1: 52094batch [01:45, 491.85batch/s]\u001b[A\n",
      "Epoch 1: 52144batch [01:45, 491.84batch/s]\u001b[A\n",
      "Epoch 1: 52194batch [01:45, 491.52batch/s]\u001b[A\n",
      "Epoch 1: 52244batch [01:46, 491.36batch/s]\u001b[A\n",
      "Epoch 1: 52294batch [01:46, 491.21batch/s]\u001b[A\n",
      "Epoch 1: 52344batch [01:46, 491.27batch/s]\u001b[A\n",
      "Epoch 1: 52394batch [01:46, 491.25batch/s]\u001b[A\n",
      "Epoch 1: 52444batch [01:46, 491.18batch/s]\u001b[A\n",
      "Epoch 1: 52494batch [01:46, 490.98batch/s]\u001b[A\n",
      "Epoch 1: 52544batch [01:46, 490.85batch/s]\u001b[A\n",
      "Epoch 1: 52594batch [01:46, 490.85batch/s]\u001b[A\n",
      "Epoch 1: 52644batch [01:46, 490.81batch/s]\u001b[A\n",
      "Epoch 1: 52694batch [01:46, 490.81batch/s]\u001b[A\n",
      "Epoch 1: 52744batch [01:47, 490.87batch/s]\u001b[A\n",
      "Epoch 1: 52794batch [01:47, 490.90batch/s]\u001b[A\n",
      "Epoch 1: 52844batch [01:47, 490.86batch/s]\u001b[A\n",
      "Epoch 1: 52894batch [01:47, 491.01batch/s]\u001b[A\n",
      "Epoch 1: 52944batch [01:47, 488.89batch/s]\u001b[A\n",
      "Epoch 1: 52993batch [01:47, 488.73batch/s]\u001b[A\n",
      "Epoch 1: 53043batch [01:47, 489.97batch/s]\u001b[A\n",
      "Epoch 1: 53092batch [01:47, 487.20batch/s]\u001b[A\n",
      "Epoch 1: 53141batch [01:47, 481.61batch/s]\u001b[A\n",
      "Epoch 1: 53190batch [01:48, 473.87batch/s]\u001b[A\n",
      "Epoch 1: 53240batch [01:48, 479.29batch/s]\u001b[A\n",
      "Epoch 1: 53290batch [01:48, 483.20batch/s]\u001b[A\n",
      "Epoch 1: 53340batch [01:48, 486.13batch/s]\u001b[A\n",
      "Epoch 1: 53390batch [01:48, 488.06batch/s]\u001b[A\n",
      "Epoch 1: 53440batch [01:48, 489.40batch/s]\u001b[A\n",
      "Epoch 1: 53490batch [01:48, 490.54batch/s]\u001b[A\n",
      "Epoch 1: 53540batch [01:48, 491.41batch/s]\u001b[A\n",
      "Epoch 1: 53590batch [01:48, 491.96batch/s]\u001b[A\n",
      "Epoch 1: 53640batch [01:48, 492.30batch/s]\u001b[A\n",
      "Epoch 1: 53690batch [01:49, 492.53batch/s]\u001b[A\n",
      "Epoch 1: 53740batch [01:49, 492.44batch/s]\u001b[A\n",
      "Epoch 1: 53790batch [01:49, 492.61batch/s]\u001b[A\n",
      "Epoch 1: 53840batch [01:49, 492.87batch/s]\u001b[A\n",
      "Epoch 1: 53890batch [01:49, 493.02batch/s]\u001b[A\n",
      "Epoch 1: 53940batch [01:49, 491.79batch/s]\u001b[A\n",
      "Epoch 1: 53990batch [01:49, 492.20batch/s]\u001b[A\n",
      "Epoch 1: 54040batch [01:49, 492.26batch/s]\u001b[A\n",
      "Epoch 1: 54090batch [01:49, 492.67batch/s]\u001b[A\n",
      "Epoch 1: 54140batch [01:49, 493.05batch/s]\u001b[A\n",
      "Epoch 1: 54190batch [01:50, 493.19batch/s]\u001b[A\n",
      "Epoch 1: 54240batch [01:50, 493.30batch/s]\u001b[A\n",
      "Epoch 1: 54290batch [01:50, 493.35batch/s]\u001b[A\n",
      "Epoch 1: 54340batch [01:50, 493.35batch/s]\u001b[A\n",
      "Epoch 1: 54390batch [01:50, 493.32batch/s]\u001b[A\n",
      "Epoch 1: 54440batch [01:50, 493.36batch/s]\u001b[A\n",
      "Epoch 1: 54490batch [01:50, 493.54batch/s]\u001b[A\n",
      "Epoch 1: 54540batch [01:50, 493.42batch/s]\u001b[A\n",
      "Epoch 1: 54590batch [01:50, 493.35batch/s]\u001b[A\n",
      "Epoch 1: 54640batch [01:50, 493.43batch/s]\u001b[A\n",
      "Epoch 1: 54690batch [01:51, 493.12batch/s]\u001b[A\n",
      "Epoch 1: 54740batch [01:51, 492.89batch/s]\u001b[A\n",
      "Epoch 1: 54790batch [01:51, 493.19batch/s]\u001b[A\n",
      "Epoch 1: 54840batch [01:51, 493.03batch/s]\u001b[A\n",
      "Epoch 1: 54890batch [01:51, 490.14batch/s]\u001b[A\n",
      "Epoch 1: 54940batch [01:51, 491.05batch/s]\u001b[A\n",
      "Epoch 1: 54990batch [01:51, 491.39batch/s]\u001b[A\n",
      "Epoch 1: 55040batch [01:51, 491.86batch/s]\u001b[A\n",
      "Epoch 1: 55090batch [01:51, 492.22batch/s]\u001b[A\n",
      "Epoch 1: 55140batch [01:51, 492.49batch/s]\u001b[A\n",
      "Epoch 1: 55190batch [01:52, 492.76batch/s]\u001b[A\n",
      "Epoch 1: 55240batch [01:52, 492.89batch/s]\u001b[A\n",
      "Epoch 1: 55290batch [01:52, 492.97batch/s]\u001b[A\n",
      "Epoch 1: 55340batch [01:52, 492.98batch/s]\u001b[A\n",
      "Epoch 1: 55390batch [01:52, 493.08batch/s]\u001b[A\n",
      "Epoch 1: 55440batch [01:52, 493.17batch/s]\u001b[A\n",
      "Epoch 1: 55490batch [01:52, 493.21batch/s]\u001b[A\n",
      "Epoch 1: 55540batch [01:52, 492.99batch/s]\u001b[A\n",
      "Epoch 1: 55590batch [01:52, 493.40batch/s]\u001b[A\n",
      "Epoch 1: 55640batch [01:52, 493.21batch/s]\u001b[A\n",
      "Epoch 1: 55690batch [01:53, 493.52batch/s]\u001b[A\n",
      "Epoch 1: 55740batch [01:53, 493.35batch/s]\u001b[A\n",
      "Epoch 1: 55790batch [01:53, 493.36batch/s]\u001b[A\n",
      "Epoch 1: 55840batch [01:53, 493.53batch/s]\u001b[A\n",
      "Epoch 1: 55890batch [01:53, 493.45batch/s]\u001b[A\n",
      "Epoch 1: 55940batch [01:53, 493.35batch/s]\u001b[A\n",
      "Epoch 1: 55990batch [01:53, 493.26batch/s]\u001b[A\n",
      "Epoch 1: 56040batch [01:53, 493.22batch/s]\u001b[A\n",
      "Epoch 1: 56090batch [01:53, 493.29batch/s]\u001b[A\n",
      "Epochs: 100%|| 1/1 [01:54<00:00, 114.33s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS is available and set the device accordingly\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "window_length = 100  # Example window length\n",
    "dataset = TrajectoryDataset(dataframe=train_df, window_length=window_length)\n",
    "batch_size = 128\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model hyperparameters\n",
    "input_size = window_length  # Window length minus 1 (since the last column is the target)\n",
    "hidden_size = 512\n",
    "output_size = 1  # Single output for time series forecast (next value)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = MLP(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# Training loop with tqdm for progress tracking\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\", unit=\"epoch\"):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    # Use tqdm to track batch progress within each epoch\n",
    "    for batch_idx, data in tqdm(enumerate(dataloader), desc=f\"Epoch {epoch + 1}\", unit=\"batch\", leave=False):\n",
    "        # Separate inputs and targets\n",
    "        inputs = data[:, :-1].to(device)  # All except last column\n",
    "        targets = data[:, -1].to(device)  # Last column is the target (next value)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss per epoch\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f66e996-5c46-462c-aed9-cd00122c8c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Generating validation predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|| 1500/1500 [00:00<00:00, 2566.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics:\n",
      "MSE: 0.002015\n",
      "MAE: 0.029032\n",
      "RMSE: 0.044890\n",
      "\n",
      "Generating test predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|| 1500/1500 [00:00<00:00, 2560.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert validation and test data to tensors\n",
    "train_set = torch.tensor(train_df.values[:,:].astype(np.float32), dtype=torch.float32).to(device)\n",
    "val_set = torch.tensor(val_df.values[:,:].astype(np.float32), dtype=torch.float32).to(device)\n",
    "test_set = torch.tensor(test_df.values[:,:].astype(np.float32), dtype=torch.float32).to(device)\n",
    "\n",
    "# Define points to predict based on validation set shape\n",
    "points_to_predict = val_set.shape[1]\n",
    "\n",
    "def autoregressive_predict(model, input_matrix, prediction_length=None):\n",
    "    \"\"\"\n",
    "    Perform memory-efficient autoregressive prediction using the trained model.\n",
    "    \n",
    "    Args:\n",
    "    - model: The trained PyTorch model\n",
    "    - input_matrix: Initial input matrix (shape: batch_size x window_length)\n",
    "    - prediction_length: Length of future trajectory to predict\n",
    "    \n",
    "    Returns:\n",
    "    - Predicted trajectories tensor\n",
    "    \"\"\"\n",
    "    if prediction_length is None:\n",
    "        prediction_length = points_to_predict\n",
    "        \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    batch_size = input_matrix.shape[0]\n",
    "    output_matrix = torch.empty(batch_size, 0, device=device)\n",
    "    current_input = input_matrix.clone()\n",
    "    \n",
    "    # Use batch processing for memory efficiency\n",
    "    with torch.no_grad():\n",
    "        for step in tqdm(range(prediction_length), desc=\"Generating predictions\"):\n",
    "            # Process predictions in batches\n",
    "            predictions = model(current_input)\n",
    "            \n",
    "            # Append predictions\n",
    "            output_matrix = torch.cat((output_matrix, predictions), dim=1)\n",
    "            \n",
    "            # Update input sequence for next prediction\n",
    "            current_input = torch.cat((current_input[:, 1:], predictions), dim=1)\n",
    "            \n",
    "            # Optional: Free up memory\n",
    "            if step % 100 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    return output_matrix\n",
    "\n",
    "# Start evaluation process\n",
    "print(\"Starting evaluation...\")\n",
    "\n",
    "# Get initial input sequence\n",
    "initial_input = train_set[:, -window_length:]\n",
    "\n",
    "# Generate predictions for validation set\n",
    "print(\"Generating validation predictions...\")\n",
    "val_predictions = autoregressive_predict(model, initial_input)\n",
    "\n",
    "# Calculate metrics\n",
    "with torch.no_grad():\n",
    "    # MSE Loss\n",
    "    mse_loss = nn.MSELoss()\n",
    "    validation_mse = mse_loss(val_predictions, val_set)\n",
    "    \n",
    "    # Additional metrics\n",
    "    mae = torch.abs(val_predictions - val_set).mean()\n",
    "    rmse = torch.sqrt(validation_mse)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"MSE: {validation_mse.item():.6f}\")\n",
    "print(f\"MAE: {mae.item():.6f}\")\n",
    "print(f\"RMSE: {rmse.item():.6f}\")\n",
    "\n",
    "# Visualization for the first three sequences\n",
    "# Create three separate plots\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    \n",
    "    # Get trajectory for validation region (first 100 points)\n",
    "    trajectory = val_predictions_np[i, :100]\n",
    "    \n",
    "    # Plot with specified formatting\n",
    "    plt.plot(trajectory, \n",
    "             color='black',\n",
    "             linewidth=3,\n",
    "             linestyle='-')\n",
    "    \n",
    "    plt.title(f'Trajectory {i}')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Ensure consistent axis limits across plots\n",
    "    plt.ylim(0, max(val_predictions_np[:3, :100].max() * 1.1, 0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'trajectory_img{i}.png', dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "# Generate test predictions\n",
    "print(\"\\nGenerating test predictions...\")\n",
    "initial_input = val_predictions[:, -window_length:]\n",
    "test_predictions = autoregressive_predict(model, initial_input)\n",
    "\n",
    "# Save predictions if needed\n",
    "try:\n",
    "    torch.save({\n",
    "        'validation_predictions': val_predictions.cpu(),\n",
    "        'test_predictions': test_predictions.cpu(),\n",
    "        'metrics': {\n",
    "            'mse': validation_mse.item(),\n",
    "            'mae': mae.item(),\n",
    "            'rmse': rmse.item()\n",
    "        }\n",
    "    }, 'prediction_results.pt')\n",
    "except Exception as e:\n",
    "    print(f\"Error saving results: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b82cf1-06cb-4ebf-97b7-d7808042fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Negative values detected. Clipping to 0...\n",
      "Submission file created successfully with 2889000 predictions\n",
      "\n",
      "First few predictions:\n",
      "                           ids     value\n",
      "0  2008-11-20 01_traffic_val_0  0.019827\n",
      "1  2008-11-20 01_traffic_val_1  0.021939\n",
      "2  2008-11-20 01_traffic_val_2  0.021669\n",
      "3  2008-11-20 01_traffic_val_3  0.016623\n",
      "4  2008-11-20 01_traffic_val_4  0.018902\n",
      "\n",
      "Last few predictions:\n",
      "                                    ids     value\n",
      "2888995  2009-03-31 00_traffic_test_958  0.098091\n",
      "2888996  2009-03-31 00_traffic_test_959  0.081974\n",
      "2888997  2009-03-31 00_traffic_test_960  0.087486\n",
      "2888998  2009-03-31 00_traffic_test_961  0.090306\n",
      "2888999  2009-03-31 00_traffic_test_962  0.056568\n"
     ]
    }
   ],
   "source": [
    "def generate_submissions_v4(pred_val_tensor, pred_test_tensor, original_val_path, original_test_path):\n",
    "    \"\"\"\n",
    "    Generate competition submission file from model predictions.\n",
    "    \n",
    "    Args:\n",
    "    - pred_val_tensor: Validation predictions tensor\n",
    "    - pred_test_tensor: Test predictions tensor\n",
    "    - original_val_path: Path to original validation CSV\n",
    "    - original_test_path: Path to original test CSV\n",
    "    \"\"\"\n",
    "    # Read the original validation and testing datasets\n",
    "    original_val_df = pd.read_csv(original_val_path)\n",
    "    original_test_df = pd.read_csv(original_test_path)\n",
    "    \n",
    "    # Verify tensor shapes\n",
    "    assert pred_val_tensor.shape[0] * pred_val_tensor.shape[1] == original_val_df.shape[0] * (original_val_df.shape[1] - 1), \\\n",
    "        \"Validation predictions shape mismatch\"\n",
    "    assert pred_test_tensor.shape[0] * pred_test_tensor.shape[1] == original_test_df.shape[0] * (original_test_df.shape[1] - 1), \\\n",
    "        \"Test predictions shape mismatch\"\n",
    "    \n",
    "    # Create empty lists to store ids and values\n",
    "    ids = []\n",
    "    values = []\n",
    "    \n",
    "    # Move tensors to CPU and convert to numpy if needed\n",
    "    if torch.is_tensor(pred_val_tensor):\n",
    "        pred_val_tensor = pred_val_tensor.cpu().numpy()\n",
    "    if torch.is_tensor(pred_test_tensor):\n",
    "        pred_test_tensor = pred_test_tensor.cpu().numpy()\n",
    "    \n",
    "    # Process validation set\n",
    "    for col_idx, col in enumerate(original_val_df.columns[1:]):  # Skip the 'ids' column\n",
    "        for row_idx, _ in enumerate(original_val_df[col]):\n",
    "            ids.append(str(f\"{col}_traffic_val_{row_idx}\"))\n",
    "            values.append(float(pred_val_tensor[row_idx, col_idx]))\n",
    "    \n",
    "    # Process testing set\n",
    "    for col_idx, col in enumerate(original_test_df.columns[1:]):  # Skip the 'ids' column\n",
    "        for row_idx, _ in enumerate(original_test_df[col]):\n",
    "            ids.append(str(f\"{col}_traffic_test_{row_idx}\"))\n",
    "            values.append(float(pred_test_tensor[row_idx, col_idx]))\n",
    "    \n",
    "    # Create the submissions dataframe\n",
    "    submissions_df = pd.DataFrame({\n",
    "        \"ids\": ids,\n",
    "        \"value\": values\n",
    "    })\n",
    "    \n",
    "    # Verify data quality\n",
    "    # Check for NaN values\n",
    "    if submissions_df.isna().any().any():\n",
    "        print(\"Warning: NaN values detected in predictions. Filling with 100...\")\n",
    "        submissions_df.fillna(100, inplace=True)\n",
    "    \n",
    "    # Check for negative values\n",
    "    if (submissions_df['value'] < 0).any():\n",
    "        print(\"Warning: Negative values detected. Clipping to 0...\")\n",
    "        submissions_df['value'] = submissions_df['value'].clip(lower=0)\n",
    "    \n",
    "    # Final assertions\n",
    "    assert submissions_df.shape[1] == 2, \"Submission should have exactly 2 columns\"\n",
    "    assert submissions_df.shape[0] == (original_val_df.shape[0] * (original_val_df.shape[1] - 1)) + \\\n",
    "           (original_test_df.shape[0] * (original_test_df.shape[1] - 1)), \"Incorrect number of predictions\"\n",
    "    assert \"ids\" in submissions_df.columns, \"Missing 'ids' column\"\n",
    "    assert \"value\" in submissions_df.columns, \"Missing 'value' column\"\n",
    "    \n",
    "    # Save to CSV without index\n",
    "    submissions_df.to_csv('submissions.csv', index=False)\n",
    "    print(f\"Submission file created successfully with {len(submissions_df)} predictions\")\n",
    "    \n",
    "    # Print sample of predictions\n",
    "    print(\"\\nFirst few predictions:\")\n",
    "    print(submissions_df.head())\n",
    "    print(\"\\nLast few predictions:\")\n",
    "    print(submissions_df.tail())\n",
    "\n",
    "# Generate submission file\n",
    "generate_submissions_v4(\n",
    "    val_predictions,\n",
    "    test_predictions,\n",
    "    '/home/pkancha3/Desktop/val.csv',\n",
    "    '/home/pkancha3/Desktop/test.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa37cca-03a5-4a97-9cd6-93ef52517875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
